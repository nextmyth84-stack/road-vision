# =====================================
# app.py â€” ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì • v7.17.2 (ì™„ì „ë³¸)
# =====================================
import streamlit as st
from openai import OpenAI
import base64, re, json, os, difflib

st.set_page_config(page_title="ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì •", layout="wide")
st.markdown("<h3 style='text-align:center; font-size:22px;'>ğŸš— ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì •</h3>", unsafe_allow_html=True)

# =====================================
# OpenAI API ì´ˆê¸°í™”
# =====================================
try:
    client = OpenAI(api_key=st.secrets["general"]["OPENAI_API_KEY"])
except Exception:
    st.error("âš ï¸ OPENAI_API_KEY ì„¤ì • í•„ìš”")
    st.stop()
MODEL_NAME = "gpt-4o"

# =====================================
# íŒŒì¼ ìœ í‹¸ í•¨ìˆ˜
# =====================================
def load_json(path, default=None):
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return default or []
    return default or []

def save_json(path, data):
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"{path} ì €ì¥ ì‹¤íŒ¨: {e}")

# =====================================
# êµì •ìš© í•œê¸€ ìëª¨ ë¶„ë¦¬/ë¹„êµ
# =====================================
CHO_LIST = list("ã„±ã„²ã„´ã„·ã„¸ã„¹ã…ã…‚ã…ƒã……ã…†ã…‡ã…ˆã…‰ã…Šã…‹ã…Œã…ã…")
JUNG_LIST = list("ã…ã…ã…‘ã…’ã…“ã…”ã…•ã…–ã…—ã…˜ã…™ã…šã…›ã…œã…ã…ã…Ÿã… ã…¡ã…¢ã…£")
JONG_LIST = [""] + list("ã„±ã„²ã„³ã„´ã„µã„¶ã„·ã„¹ã„ºã„»ã„¼ã„½ã„¾ã„¿ã…€ã…ã…‚ã…„ã……ã…†ã…‡ã…ˆã…Šã…‹ã…Œã…ã…")

# (ê¸°ì¡´ ê²ƒì„ ì´ ë¸”ë¡ìœ¼ë¡œ êµì²´)
CONFUSABLES = {
    # ì´ˆì„±/ì¢…ì„± ìì£¼ í—·ê°ˆë¦¼
    'ã…': ['ã…‚'], 'ã…‚': ['ã…'],
    'ã„´': ['ã„¹'], 'ã„¹': ['ã„´'],
    'ã„±': ['ã…‹'], 'ã…‹': ['ã„±'],
    'ã……': ['ã…ˆ','ã…Š'], 'ã…ˆ': ['ã……','ã…Š'], 'ã…Š': ['ã…ˆ','ã……'],

    # ì¤‘ì„± ìì£¼ í—·ê°ˆë¦¼
    'ã…': ['ã…”'], 'ã…”': ['ã…'],
    'ã…¡': ['ã…œ'], 'ã…œ': ['ã…¡'],   # â˜… ì€â†”ìš´ ì¼€ì´ìŠ¤ ì¡ëŠ” í•µì‹¬
    # (í•„ìš”í•˜ë©´ ì¶”ê°€)
    # 'ã…“': ['ã…—'], 'ã…—': ['ã…“'],
    # 'ã…•': ['ã…‘'], 'ã…‘': ['ã…•'],
}


def split_hangul(c):
    code = ord(c) - 0xAC00
    cho = code // 588
    jung = (code - cho * 588) // 28
    jong = code % 28
    return cho, jung, jong

def similar_jamo(a, b):
    return a == b or (a in CONFUSABLES and b in CONFUSABLES[a])

def hangul_similarity(a, b):
    """ìëª¨ ìœ ì‚¬ë„ (OCR í˜¼ë™ í—ˆìš© í¬í•¨)"""
    if not a or not b:
        return 0
    score = 0
    total = max(len(a), len(b))
    for i in range(min(len(a), len(b))):
        ca, cb = a[i], b[i]
        if not ('ê°€' <= ca <= 'í£' and 'ê°€' <= cb <= 'í£'):
            score += 1 if ca == cb else 0
            continue
        cho_a, jung_a, jong_a = split_hangul(ca)
        cho_b, jung_b, jong_b = split_hangul(cb)
        s = 0
        if similar_jamo(CHO_LIST[cho_a], CHO_LIST[cho_b]): s += 0.4
        if similar_jamo(JUNG_LIST[jung_a], JUNG_LIST[jung_b]): s += 0.4
        if similar_jamo(JONG_LIST[jong_a], JONG_LIST[jong_b]): s += 0.2
        score += s
    return score / total

def correct_name_v2(name, valid_names, cutoff=0.6):
    """ì „ì²´ ê·¼ë¬´ì ê¸°ì¤€ ê³ ê¸‰ ì˜¤íƒ€ êµì •"""
    if not name or not valid_names:
        return name
    name_norm = re.sub(r"[^ê°€-í£]", "", name)
    best_match, best_score = None, 0
    for valid in valid_names:
        score = hangul_similarity(name_norm, valid)
        if score > best_score:
            best_match, best_score = valid, score
    return best_match if best_score >= cutoff else name

def normalize_name(s):
    return re.sub(r"[^ê°€-í£]", "", re.sub(r"\(.*?\)", "", s or ""))

# =====================================
# ê¸°ë³¸ JSON íŒŒì¼ë“¤
# =====================================
EMP_FILE = "employee_list.json"
PREV_FILE = "ì „ì¼ê·¼ë¬´.json"
COURSE_FILE = "course_result.json"

# =====================================
# ì „ì²´ ê·¼ë¬´ì ê´€ë¦¬
# =====================================
st.sidebar.header("ê·¼ë¬´ ë°ì´í„° ê´€ë¦¬")
with st.sidebar.expander("ğŸ‘¥ ì „ì²´ ê·¼ë¬´ìëª…ë‹¨", expanded=False):
    default_emp = [
        "ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ì„±ì—°","ê¹€ì§€ì€","ì•ˆìœ ë¯¸",
        "ìœ¤ì—¬í—Œ","ìœ¤ì›ì‹¤","ì´ë‚˜ë˜","ì´í˜¸ì„","ì¡°ìœ¤ì˜","ì¡°ì •ë˜","ê¹€ë³‘ìš±","ê¹€ì£¼í˜„"
    ]
    employee_list = load_json(EMP_FILE, default_emp)
    emp_edit = st.text_area("ì „ì²´ ê·¼ë¬´ì", "\n".join(employee_list), height=180)
    if st.button("ğŸ’¾ ê·¼ë¬´ìëª…ë‹¨ ì €ì¥"):
        new_list = [x.strip() for x in emp_edit.splitlines() if x.strip()]
        save_json(EMP_FILE, new_list)
        st.sidebar.success("ì „ì²´ ê·¼ë¬´ì ì €ì¥ ì™„ë£Œ")

# =====================================
# ìˆœë²ˆ/ì°¨ëŸ‰í‘œ íŒŒì¼ ì •ì˜
# =====================================
KEY_FILE  = "data_key.json"
GY_FILE   = "data_gyoyang.json"
SUD_FILE  = "data_sudong.json"
VEH1_FILE = "veh1.json"
VEH2_FILE = "veh2.json"

# ê¸°ë³¸ê°’
default_key = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ì„±ì—°","ê¹€ì§€ì€","ì•ˆìœ ë¯¸","ìœ¤ì—¬í—Œ","ìœ¤ì›ì‹¤","ì´ë‚˜ë˜","ì´í˜¸ì„","ì¡°ìœ¤ì˜","ì¡°ì •ë˜"]
default_gy  = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ë³‘ìš±","ê¹€ì„±ì—°","ê¹€ì£¼í˜„","ê¹€ì§€ì€","ì•ˆìœ ë¯¸","ì´í˜¸ì„","ì¡°ì •ë˜"]
default_sd  = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ì„±ì—°","ê¹€ì£¼í˜„","ì´í˜¸ì„","ì¡°ì •ë˜"]
default_veh1 = ["2í˜¸ ì¡°ì •ë˜","5í˜¸ ê¶Œí•œì†”","7í˜¸ ê¹€ë‚¨ê· ","8í˜¸ ì´í˜¸ì„","9í˜¸ ê¹€ì£¼í˜„","10í˜¸ ê¹€ì„±ì—°"]
default_veh2 = ["4í˜¸ ê¹€ë‚¨ê· ","5í˜¸ ê¹€ë³‘ìš±","6í˜¸ ê¹€ì§€ì€","12í˜¸ ì•ˆìœ ë¯¸","14í˜¸ ê¹€ë©´ì •","15í˜¸ ì´í˜¸ì„","17í˜¸ ê¹€ì„±ì—°","18í˜¸ ê¶Œí•œì†”","19í˜¸ ê¹€ì£¼í˜„","22í˜¸ ì¡°ì •ë˜"]

# íŒŒì¼ ë¡œë“œ
key_order   = load_json(KEY_FILE,  default_key)
gyoyang_ord = load_json(GY_FILE,   default_gy)
sudong_ord  = load_json(SUD_FILE,  default_sd)
veh1_lines  = load_json(VEH1_FILE, default_veh1)
veh2_lines  = load_json(VEH2_FILE, default_veh2)

# -------------------------------------
# ì‚¬ì´ë“œë°”: ìˆœë²ˆ/ì°¨ëŸ‰í‘œ(ìˆ¨ê¹€ â†’ ìˆ˜ì •/ì €ì¥)
# -------------------------------------
st.sidebar.markdown("---")
with st.sidebar.expander("ğŸ”‘ ì—´ì‡  ìˆœë²ˆ", expanded=False):
    key_edit = st.text_area("ì—´ì‡  ìˆœë²ˆ", "\n".join(key_order), height=150)
    if st.button("ğŸ’¾ ì—´ì‡  ì €ì¥"):
        save_json(KEY_FILE, [x.strip() for x in key_edit.splitlines() if x.strip()])
        st.sidebar.success("ì—´ì‡  ìˆœë²ˆ ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸ“˜ êµì–‘ ìˆœë²ˆ", expanded=False):
    gy_edit = st.text_area("êµì–‘ ìˆœë²ˆ", "\n".join(gyoyang_ord), height=150)
    if st.button("ğŸ’¾ êµì–‘ ì €ì¥"):
        save_json(GY_FILE, [x.strip() for x in gy_edit.splitlines() if x.strip()])
        st.sidebar.success("êµì–‘ ìˆœë²ˆ ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸ§° 1ì¢… ìˆ˜ë™ ìˆœë²ˆ", expanded=False):
    sd_edit = st.text_area("1ì¢… ìˆ˜ë™ ìˆœë²ˆ", "\n".join(sudong_ord), height=150)
    if st.button("ğŸ’¾ 1ì¢… ì €ì¥"):
        save_json(SUD_FILE, [x.strip() for x in sd_edit.splitlines() if x.strip()])
        st.sidebar.success("1ì¢… ìˆ˜ë™ ìˆœë²ˆ ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸš— ì°¨ëŸ‰í‘œ (1ì¢…/2ì¢…)", expanded=False):
    v1_edit = st.text_area("1ì¢… ìˆ˜ë™ ì°¨ëŸ‰í‘œ", "\n".join(veh1_lines), height=120)
    v2_edit = st.text_area("2ì¢… ìë™ ì°¨ëŸ‰í‘œ", "\n".join(veh2_lines), height=160)
    if st.button("ğŸ’¾ ì°¨ëŸ‰í‘œ ì €ì¥"):
        save_json(VEH1_FILE, [x.strip() for x in v1_edit.splitlines() if x.strip()])
        save_json(VEH2_FILE, [x.strip() for x in v2_edit.splitlines() if x.strip()])
        st.sidebar.success("ì°¨ëŸ‰í‘œ ì €ì¥ ì™„ë£Œ")

sudong_count = st.sidebar.radio("1ì¢… ìˆ˜ë™ ì¸ì›ìˆ˜", [1, 2], index=0)
repair_cars = [x.strip() for x in st.sidebar.text_input("ì •ë¹„ ì°¨ëŸ‰ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="").split(",") if x.strip()]

# ì „ì¼ê°’ ë¡œë“œ/í‘œì‹œ
prev_data = load_json(PREV_FILE, {"ì—´ì‡ ":"", "êµì–‘_5êµì‹œ":"", "1ì¢…ìˆ˜ë™":""})
prev_key  = prev_data.get("ì—´ì‡ ","")
prev_gy5  = prev_data.get("êµì–‘_5êµì‹œ","")
prev_sd   = prev_data.get("1ì¢…ìˆ˜ë™","")
st.sidebar.info(f"ì „ì¼ ê¸°ì¤€ â†’ ì—´ì‡ :{prev_key or '-'}, êµì–‘5:{prev_gy5 or '-'}, 1ì¢…:{prev_sd or '-'}")

# =====================================
# GPT OCR: ê·¼ë¬´ì/ì œì™¸ì/ì¡°í‡´/ì§€ê° ì¶”ì¶œ
# =====================================
def gpt_extract(img_bytes, want_early=False, want_late=False, want_excluded=False):
    b64 = base64.b64encode(img_bytes).decode()
    user = (
        "ì´ ì´ë¯¸ì§€ëŠ” ìš´ì „ë©´í—ˆì‹œí—˜ ê·¼ë¬´í‘œì…ë‹ˆë‹¤.\n"
        "1) ë„ë¡œì£¼í–‰ ê·¼ë¬´ì ì´ë¦„ë§Œ names ë°°ì—´ì— ì¶”ì¶œ.\n"
        "2) ê´„í˜¸(A-í•©, B-ë¶ˆ ë“±)ëŠ” ê·¸ëŒ€ë¡œ ë‘ë˜, JSONì—ëŠ” ê´„í˜¸ í¬í•¨ ì›ë¬¸ì„ namesì— ë„£ìœ¼ì„¸ìš”.\n"
        "3) 'íœ´ê°€, êµìœ¡, ì¶œì¥, ê³µê°€, ì—°ê°€, ì—°ì°¨, ëŒë´„' í‘œê¸°ëœ ì´ë¦„ì€ excluded ë°°ì—´ì— ë„£ìœ¼ì„¸ìš”.\n"
        + ("4) 'ì¡°í‡´:'ê°€ ìˆìœ¼ë©´ early_leave: [{name, time(ìˆ«ì)}].\n" if want_early else "")
        + ("5) '10ì‹œ ì¶œê·¼' ë˜ëŠ” 'ì™¸ì¶œ:'ì´ ìˆìœ¼ë©´ late_start: [{name, time(ìˆ«ì)}].\n" if want_late else "")
        + "ë°˜í™˜ ì˜ˆ: {\"names\":[\"ê¹€ì„±ì—°(A-í•©)\",\"ì´í˜¸ì„(B-ë¶ˆ)\"],"
          "\"excluded\":[\"ìœ¤ì›ì‹¤\"],"
          "\"early_leave\":[{\"name\":\"ê¹€ë³‘ìš±\",\"time\":14}],"
          "\"late_start\":[{\"name\":\"ì•ˆìœ ë¯¸\",\"time\":10}]}"
    )
    try:
        res = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role":"system","content":"í‘œì—ì„œ ì´ë¦„/ì œì™¸ì ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œ"},
                {"role":"user","content":[
                    {"type":"text","text":user},
                    {"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{b64}"}}
                ]}
            ]
        )
        raw = res.choices[0].message.content
        js = json.loads(re.search(r"\{.*\}", raw, re.S).group(0))
        return (
            js.get("names", []),
            js.get("excluded", []),
            js.get("early_leave", []) if want_early else [],
            js.get("late_start", []) if want_late else []
        )
    except Exception as e:
        st.error(f"OCR ì‹¤íŒ¨: {e}")
        return [], [], [], []

# =====================================
# 1) ì´ë¯¸ì§€ ì—…ë¡œë“œ & OCR ì‹¤í–‰
# =====================================
st.markdown("<h4 style='margin-top:6px;'>1ï¸âƒ£ ê·¼ë¬´í‘œ ì´ë¯¸ì§€ ì—…ë¡œë“œ & OCR</h4>", unsafe_allow_html=True)
c1, c2 = st.columns(2)
with c1: m_file = st.file_uploader("ğŸ“¸ ì˜¤ì „ ê·¼ë¬´í‘œ", type=["png","jpg","jpeg"])
with c2: a_file = st.file_uploader("ğŸ“¸ ì˜¤í›„ ê·¼ë¬´í‘œ", type=["png","jpg","jpeg"])

b1, b2 = st.columns(2)
with b1:
    if st.button("ğŸ§  ì˜¤ì „ GPT ì¸ì‹"):
        if not m_file:
            st.warning("ì˜¤ì „ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            with st.spinner("ì˜¤ì „ GPT ë¶„ì„ ì¤‘..."):
                m_names, excluded_auto, _, late = gpt_extract(m_file.read(), want_late=True, want_excluded=True)
                st.session_state.m_names_raw = m_names
                st.session_state.excluded_auto = excluded_auto
                st.session_state.late_start = late
                st.success(f"ì˜¤ì „ ì¸ì‹ â†’ ê·¼ë¬´ì {len(m_names)}ëª…, ì œì™¸ì {len(excluded_auto)}ëª…")

with b2:
    if st.button("ğŸ§  ì˜¤í›„ GPT ì¸ì‹"):
        if not a_file:
            st.warning("ì˜¤í›„ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            with st.spinner("ì˜¤í›„ GPT ë¶„ì„ ì¤‘..."):
                a_names, _, early, _ = gpt_extract(a_file.read(), want_early=True)
                st.session_state.a_names_raw = a_names
                st.session_state.early_leave = early
                st.success(f"ì˜¤í›„ ì¸ì‹ â†’ ê·¼ë¬´ì {len(a_names)}ëª…, ì¡°í‡´ {len(early)}ëª…")

# =====================================
# 2) ì¸ì‹ ê²°ê³¼ í™•ì¸/ìˆ˜ì • (ìŠ¤í¬ë¡¤ ì ìš©)
# =====================================
# ê·¼ë¬´ì œì™¸ì íƒ€ì´í‹€ (ì‘ê²Œ)
st.markdown("<h6 style='font-size:15px; font-weight:bold; margin-top:10px;'>ê·¼ë¬´ì œì™¸ì</h6>", unsafe_allow_html=True)
excluded_raw = "\n".join(st.session_state.get("excluded_auto", []))
excluded_text = st.text_area("ìë™ì¶”ì¶œ í›„ ìˆ˜ì • ê°€ëŠ¥", excluded_raw, height=110, label_visibility="collapsed")

st.markdown("<h5 style='margin-top:6px;'>ğŸŒ… ì˜¤ì „ ê·¼ë¬´ì (ìˆ˜ì • ê°€ëŠ¥)</h5>", unsafe_allow_html=True)
morning_raw = "\n".join(st.session_state.get("m_names_raw", []))
morning_text = st.text_area("ì˜¤ì „ ê·¼ë¬´ì", morning_raw, height=220)

st.markdown("<h5 style='margin-top:6px;'>ğŸŒ‡ ì˜¤í›„ ê·¼ë¬´ì (ìˆ˜ì • ê°€ëŠ¥)</h5>", unsafe_allow_html=True)
afternoon_raw = "\n".join(st.session_state.get("a_names_raw", []))
afternoon_text = st.text_area("ì˜¤í›„ ê·¼ë¬´ì", afternoon_raw, height=220)

# ë¦¬ìŠ¤íŠ¸ ë³€í™˜
m_list = [x.strip() for x in morning_text.splitlines() if x.strip()]
a_list = [x.strip() for x in afternoon_text.splitlines() if x.strip()]
excluded = {x.strip() for x in excluded_text.splitlines() if x.strip()}

# =====================================
# ë³´ì¡° í•¨ìˆ˜
# =====================================
def clipboard_copy_button(label, text):
    """Streamlit í´ë¦½ë³´ë“œ ë³µì‚¬ ë²„íŠ¼"""
    clip_id = f"copy_{abs(hash(label))}"
    html = f"""
    <button id="{clip_id}" style="background:#3b82f6;color:white;border:none;
    padding:6px 12px;border-radius:6px;cursor:pointer;margin-top:6px;">{label}</button>
    <script>
    const b = document.getElementById("{clip_id}");
    b.onclick = () => {{
      navigator.clipboard.writeText(`{text}`);
      b.innerText = "âœ… ë³µì‚¬ë¨!";
      setTimeout(()=>b.innerText="{label}",1500);
    }};
    </script>
    """
    st.markdown(html, unsafe_allow_html=True)

def extract_course_from_token(token: str):
    """ê´„í˜¸ ë‚´ 'A'/'B' + 'í•©/ë¶ˆ' ì¶”ì¶œ"""
    m = re.search(r"\((.*?)\)", token)
    if not m:
        return None
    raw = re.sub(r"[^A-Za-zê°€-í£]", "", m.group(1)).upper()
    course = "A" if "A" in raw else ("B" if "B" in raw else None)
    result = "í•©ê²©" if "í•©" in raw else ("ë¶ˆí•©ê²©" if "ë¶ˆ" in raw else None)
    if course and result:
        return course, result
    return None

def parse_vehicle_map(lines):
    m = {}
    for line in lines:
        parts = line.strip().split()
        if len(parts) >= 2:
            car = parts[0]
            name = " ".join(parts[1:])
            m[name] = car
    return m

def get_vehicle(name, veh_map):
    nkey = normalize_name(name)
    for k, v in veh_map.items():
        if normalize_name(k) == nkey:
            return v
    return ""

def mark_car(car, repair_list):
    return f"{car}{' (ì •ë¹„)' if car in repair_list else ''}" if car else ""

def pick_next_from_cycle(cycle, last, allowed_norms: set):
    """ìˆœë²ˆ ìˆœí™˜ ì„ íƒ"""
    if not cycle:
        return None
    cyc_norm = [normalize_name(x) for x in cycle]
    last_norm = normalize_name(last)
    start = (cyc_norm.index(last_norm) + 1) % len(cycle) if last_norm in cyc_norm else 0
    for i in range(len(cycle)*2):
        cand = cycle[(start+i) % len(cycle)]
        if normalize_name(cand) in allowed_norms:
            return cand
    return None

# =====================================
# 3ï¸âƒ£ ì˜¤ì „ ê·¼ë¬´ ë°°ì •
# =====================================
st.markdown("---")
st.markdown("## 3ï¸âƒ£ ì˜¤ì „ ê·¼ë¬´ ë°°ì •")

if st.button("ğŸ“‹ ì˜¤ì „ ë°°ì • ìƒì„±"):
    try:
        veh1_map = parse_vehicle_map(veh1_lines)
        veh2_map = parse_vehicle_map(veh2_lines)

        corrected_m = [correct_name_v2(x, employee_list) for x in m_list]
        course_records = []
        cleaned_m = []
        for token in corrected_m:
            info = extract_course_from_token(token)
            pure = re.sub(r"\(.*?\)", "", token).strip()
            if info:
                c, r = info
                course_records.append({"name": pure, "course": f"{c}ì½”ìŠ¤", "result": r})
            cleaned_m.append(pure)
        save_json(COURSE_FILE, course_records)

        excl_norms = {normalize_name(x) for x in excluded}
        m_norms = {normalize_name(x) for x in cleaned_m} - excl_norms

        key_filtered = [x for x in key_order if normalize_name(x) not in excl_norms]
        if key_filtered:
            knorms = [normalize_name(x) for x in key_filtered]
            pnorm = normalize_name(prev_key)
            today_key = key_filtered[(knorms.index(pnorm)+1)%len(key_filtered)] if pnorm in knorms else key_filtered[0]
        else:
            today_key = ""

        gy1 = pick_next_from_cycle(gyoyang_ord, prev_gy5, m_norms)
        gy1_norm = normalize_name(gy1) if gy1 else None
        gy2 = pick_next_from_cycle(gyoyang_ord, gy1 or prev_gy5, m_norms - ({gy1_norm} if gy1_norm else set()))

        sud_m, last_pick = [], prev_sd
        for _ in range(sudong_count):
            cand = pick_next_from_cycle(sudong_ord, last_pick, m_norms - {normalize_name(x) for x in sud_m})
            if not cand: break
            sud_m.append(cand)
            last_pick = cand

        sud_norms_m = {normalize_name(x) for x in sud_m}
        auto_m = [nm for nm in cleaned_m if normalize_name(nm) in (m_norms - sud_norms_m)]

        st.session_state["today_key"] = today_key
        st.session_state["am_gy_base_for_pm"] = gy2 or gy1 or prev_gy5
        st.session_state["am_sud_base_for_pm"] = sud_m[-1] if sud_m else prev_sd
        st.session_state["am_driver_names"] = sud_m + auto_m
        st.session_state["am_cars_1"] = [get_vehicle(x, veh1_map) for x in sud_m if get_vehicle(x, veh1_map)]
        st.session_state["am_cars_2"] = [get_vehicle(x, veh2_map) for x in auto_m if get_vehicle(x, veh2_map)]

        # ì¶œë ¥
        lines = []
        if today_key: lines.append(f"ì—´ì‡ : {today_key}")
        if gy1: lines.append(f"1êµì‹œ(êµì–‘): {gy1}")
        if gy2: lines.append(f"2êµì‹œ(êµì–‘): {gy2}")

        if sud_m:
            for nm in sud_m:
                lines.append(f"1ì¢…ìˆ˜ë™: {nm} {mark_car(get_vehicle(nm, veh1_map), repair_cars)}")
        else:
            lines.append("1ì¢…ìˆ˜ë™: (ë°°ì •ì ì—†ìŒ)")

        if auto_m:
            lines.append("2ì¢… ìë™:")
            for nm in auto_m:
                lines.append(f" â€¢ {nm} {mark_car(get_vehicle(nm, veh2_map), repair_cars)}")

        # ì½”ìŠ¤ì ê²€
        if course_records:
            lines.append("")
            lines.append("ğŸ§­ ì½”ìŠ¤ì ê²€ ê²°ê³¼:")
            for c in ["A","B"]:
                passed = [r["name"] for r in course_records if r["course"]==f"{c}ì½”ìŠ¤" and r["result"]=="í•©ê²©"]
                failed = [r["name"] for r in course_records if r["course"]==f"{c}ì½”ìŠ¤" and r["result"]=="ë¶ˆí•©ê²©"]
                if passed: lines.append(f" â€¢ {c}ì½”ìŠ¤ í•©ê²©: {', '.join(passed)}")
                if failed: lines.append(f" â€¢ {c}ì½”ìŠ¤ ë¶ˆí•©ê²©: {', '.join(failed)}")

        result_text = "\n".join(lines)
        st.markdown("### ğŸ“‹ ì˜¤ì „ ê²°ê³¼")
        st.code(result_text, language="text")
        clipboard_copy_button("ğŸ“‹ ê²°ê³¼ ë³µì‚¬í•˜ê¸°", result_text)

    except Exception as e:
        st.error(f"ì˜¤ì „ ì˜¤ë¥˜: {e}")

# =====================================
# 4ï¸âƒ£ ì˜¤í›„ ê·¼ë¬´ ë°°ì •
# =====================================
st.markdown("---")
st.markdown("## 4ï¸âƒ£ ì˜¤í›„ ê·¼ë¬´ ë°°ì •")
save_check = st.checkbox("ì´ ê²°ê³¼ë¥¼ ì „ì¼ê·¼ë¬´.jsonìœ¼ë¡œ ì €ì¥", value=True)

if st.button("ğŸ“‹ ì˜¤í›„ ë°°ì • ìƒì„±"):
    try:
        veh1_map = parse_vehicle_map(veh1_lines)
        veh2_map = parse_vehicle_map(veh2_lines)
        corrected_a = [correct_name_v2(x, employee_list) for x in a_list]
        excl_norms = {normalize_name(x) for x in excluded}
        a_norms = {normalize_name(x) for x in corrected_a} - excl_norms

        gy_start = st.session_state.get("am_gy_base_for_pm", prev_gy5)
        used = set()
        gy3 = pick_next_from_cycle(gyoyang_ord, gy_start, a_norms)
        if gy3: used.add(normalize_name(gy3))
        gy4 = pick_next_from_cycle(gyoyang_ord, gy3 or gy_start, a_norms - used)
        if gy4: used.add(normalize_name(gy4))
        gy5 = pick_next_from_cycle(gyoyang_ord, gy4 or gy3 or gy_start, a_norms - used)

        sud_base = st.session_state.get("am_sud_base_for_pm", prev_sd)
        sud_a, last_pick = [], sud_base
        for _ in range(sudong_count):
            cand = pick_next_from_cycle(sudong_ord, last_pick, a_norms)
            if not cand: break
            sud_a.append(cand)
            last_pick = cand

        sud_norms_a = {normalize_name(x) for x in sud_a}
        auto_a = [nm for nm in corrected_a if normalize_name(nm) in (a_norms - sud_norms_a)]

        today_key = st.session_state.get("today_key", prev_key)
        lines = []
        if today_key: lines.append(f"ì—´ì‡ : {today_key}")
        if gy3: lines.append(f"3êµì‹œ(êµì–‘): {gy3}")
        if gy4: lines.append(f"4êµì‹œ(êµì–‘): {gy4}")
        if gy5: lines.append(f"5êµì‹œ(êµì–‘): {gy5}")

        if sud_a:
            for nm in sud_a:
                lines.append(f"1ì¢…ìˆ˜ë™: {nm} {mark_car(get_vehicle(nm, veh1_map), repair_cars)}")
        else:
            lines.append("1ì¢…ìˆ˜ë™: (ë°°ì •ì ì—†ìŒ)")

        if auto_a:
            lines.append("2ì¢… ìë™:")
            for nm in auto_a:
                lines.append(f" â€¢ {nm} {mark_car(get_vehicle(nm, veh2_map), repair_cars)}")

        # ì˜¤ì „ ëŒ€ë¹„ ë¹„êµ
        lines.append("\nì˜¤ì „ ëŒ€ë¹„ ë¹„êµ:")
        am_drivers = st.session_state.get("am_driver_names", [])
        am_norms = {normalize_name(x) for x in am_drivers}
        pm_norms = {normalize_name(x) for x in (sud_a + auto_a)}
        new_joiners = [nm for nm in (sud_a + auto_a) if normalize_name(nm) not in am_norms]
        missing = [nm for nm in am_drivers if normalize_name(nm) not in pm_norms]
        if new_joiners: lines.append(" â€¢ ì‹ ê·œ íˆ¬ì…: " + ", ".join(sorted(new_joiners)))
        if missing: lines.append(" â€¢ ë¹ ì§„ ì¸ì›: " + ", ".join(sorted(missing)))
        if not new_joiners and not missing:
            lines.append(" â€¢ ë³€ë™ ì—†ìŒ")

        # ë¯¸ë°°ì • ì°¨ëŸ‰
        am_c1 = set(st.session_state.get("am_cars_1", []))
        am_c2 = set(st.session_state.get("am_cars_2", []))
        pm_c1 = {get_vehicle(x, veh1_map) for x in sud_a if get_vehicle(x, veh1_map)}
        pm_c2 = {get_vehicle(x, veh2_map) for x in auto_a if get_vehicle(x, veh2_map)}
        un1 = sorted([c for c in am_c1 if c and c not in pm_c1])
        un2 = sorted([c for c in am_c2 if c and c not in pm_c2])
        if un1 or un2:
            lines.append("")
            lines.append("ë¯¸ë°°ì • ì°¨ëŸ‰:")
            if un1:
                lines.append(" [1ì¢… ìˆ˜ë™]")
                for c in un1: lines.append(f"  â€¢ {c} ë§ˆê°")
            if un2:
                lines.append(" [2ì¢… ìë™]")
                for c in un2: lines.append(f"  â€¢ {c} ë§ˆê°")

        result_text = "\n".join(lines)
        st.markdown("### ğŸ“‹ ì˜¤í›„ ê²°ê³¼")
        st.code(result_text, language="text")
        clipboard_copy_button("ğŸ“‹ ê²°ê³¼ ë³µì‚¬í•˜ê¸°", result_text)

        if save_check:
            save_json(PREV_FILE, {"ì—´ì‡ ":today_key,"êµì–‘_5êµì‹œ":gy5 or gy4 or gy3 or prev_gy5,"1ì¢…ìˆ˜ë™":(sud_a[-1] if sud_a else prev_sd)})
            st.success("ì „ì¼ê·¼ë¬´.json ì—…ë°ì´íŠ¸ ì™„ë£Œ âœ…")

    except Exception as e:
        st.error(f"ì˜¤í›„ ì˜¤ë¥˜: {e}")
