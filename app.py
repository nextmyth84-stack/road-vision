# =====================================
# app.py â€” ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì • v7.18.3 (ê´„í˜¸/ë³µì‚¬ ìˆ˜ì •ì™„ì „ë³¸)
# =====================================
import streamlit as st
from openai import OpenAI
import base64, re, json, os, difflib

st.set_page_config(page_title="ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì •", layout="wide")
st.markdown("<h3 style='text-align:center; font-size:22px;'>ğŸš— ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì •</h3>", unsafe_allow_html=True)

# =====================================
# OpenAI ì´ˆê¸°í™”
# =====================================
try:
    client = OpenAI(api_key=st.secrets["general"]["OPENAI_API_KEY"])
except Exception:
    st.error("âš ï¸ OPENAI_API_KEY ì„¤ì • í•„ìš”")
    st.stop()
MODEL_NAME = "gpt-4o"

# =====================================
# JSON ìœ í‹¸
# =====================================
def load_json(path, default=None):
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return default if default is not None else []
    return default if default is not None else []

def save_json(path, data):
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"{path} ì €ì¥ ì‹¤íŒ¨: {e}")

# =====================================
# êµì • ì•Œê³ ë¦¬ì¦˜ (correct_name_v3)
# =====================================
CHO_LIST = list("ã„±ã„²ã„´ã„·ã„¸ã„¹ã…ã…‚ã…ƒã……ã…†ã…‡ã…ˆã…‰ã…Šã…‹ã…Œã…ã…")
JUNG_LIST = list("ã…ã…ã…‘ã…’ã…“ã…”ã…•ã…–ã…—ã…˜ã…™ã…šã…›ã…œã…ã…ã…Ÿã… ã…¡ã…¢ã…£")
JONG_LIST = [""] + list("ã„±ã„²ã„³ã„´ã„µã„¶ã„·ã„¹ã„ºã„»ã„¼ã„½ã„¾ã„¿ã…€ã…ã…‚ã…„ã……ã…†ã…‡ã…ˆã…Šã…‹ã…Œã…ã…")

CONFUSABLES = {
    'ã…': ['ã…‚'], 'ã…‚': ['ã…'],
    'ã„´': ['ã„¹'], 'ã„¹': ['ã„´'],
    'ã„±': ['ã…‹'], 'ã…‹': ['ã„±'],
    'ã……': ['ã…ˆ','ã…Š'], 'ã…ˆ': ['ã……','ã…Š'], 'ã…Š': ['ã…ˆ','ã……'],
    'ã…': ['ã…”'], 'ã…”': ['ã…'],
    'ã…¡': ['ã…œ'], 'ã…œ': ['ã…¡'],
}

def split_hangul(c):
    code = ord(c) - 0xAC00
    cho = code // 588
    jung = (code - cho * 588) // 28
    jong = code % 28
    return cho, jung, jong

def similar_jamo(a, b):
    return a == b or (a in CONFUSABLES and b in CONFUSABLES[a])

def hangul_similarity(a, b):
    if not a or not b: return 0
    score, total = 0, max(len(a), len(b))
    for i in range(min(len(a), len(b))):
        ca, cb = a[i], b[i]
        if not ('ê°€' <= ca <= 'í£' and 'ê°€' <= cb <= 'í£'):
            score += 1 if ca == cb else 0
            continue
        cho_a, jung_a, jong_a = split_hangul(ca)
        cho_b, jung_b, jong_b = split_hangul(cb)
        s = 0
        if similar_jamo(CHO_LIST[cho_a], CHO_LIST[cho_b]): s += 0.4
        if similar_jamo(JUNG_LIST[jung_a], JUNG_LIST[jung_b]): s += 0.4
        if similar_jamo(JONG_LIST[jong_a], JONG_LIST[jong_b]): s += 0.2
        score += s
    return score / total

def normalized_name(s):
    return re.sub(r"[^ê°€-í£]", "", s or "")

def correct_name_v3(name, valid_names, cutoff=0.6):
    if not name or not valid_names: return name
    n = normalized_name(name)
    best = (None, 0); scores = []
    for valid in valid_names:
        v = normalized_name(valid)
        jamo_score = hangul_similarity(n, v)
        seq_score = difflib.SequenceMatcher(None, n, v).ratio()
        score = (jamo_score + seq_score) / 2
        scores.append((valid, score))
        if score > best[1]: best = (valid, score)
    scores.sort(key=lambda x: x[1], reverse=True)
    if len(scores) > 1 and (scores[0][1] - scores[1][1]) < 0.08:
        return name
    return best[0] if best[1] >= cutoff else name

# normalize_name ë³„ì¹­
def normalize_name(s): 
    return normalized_name(s)

# =====================================
# ì½”ìŠ¤ ì¶”ì¶œ + ë°°ì •ìš© ì´ë¦„ ì •ë¦¬
# =====================================
def extract_course_from_token(token: str):
    m = re.search(r"\((.*?)\)", token)
    if not m: return None
    raw = re.sub(r"[^A-Za-zê°€-í£]", "", m.group(1)).upper()
    course = "A" if "A" in raw else ("B" if "B" in raw else None)
    result = "í•©ê²©" if "í•©" in raw else ("ë¶ˆí•©ê²©" if "ë¶ˆ" in raw else None)
    if course and result:
        return course, result
    return None

def split_and_clean_name_list(raw_names: list, valid_names: list):
    course_records, cleaned = [], []
    for token in raw_names:
        fixed = correct_name_v3(token, valid_names)
        info = extract_course_from_token(fixed)
        pure = re.sub(r"\(.*?\)", "", fixed).strip()
        if info:
            c, r = info
            course_records.append({"name": pure, "course": f"{c}ì½”ìŠ¤", "result": r})
        cleaned.append(pure)
    return cleaned, course_records

# =====================================
# ë³µì‚¬ë²„íŠ¼ (HTML ì •ìƒ ë Œë”ë§)
# =====================================
def clipboard_copy_button(label, text):
    btn_id = f"btn_{abs(hash(label+text))}"
    js = f"""
    <button id="{btn_id}" style="background:#2563eb;color:white;border:none;
    padding:6px 12px;border-radius:8px;cursor:pointer;margin-top:6px;">{label}</button>
    <script>
    const b=document.getElementById("{btn_id}");
    if(b) {{
        b.onclick=()=>{{navigator.clipboard.writeText(`{text}`);b.innerText="âœ… ë³µì‚¬ë¨!";
        setTimeout(()=>b.innerText="{label}",1500);}};
    }}
    </script>
    """
    st.markdown(js, unsafe_allow_html=True)

# =====================================
# íŒŒì¼ ë° ê¸°ë³¸ ë°ì´í„°
# =====================================
EMP_FILE   = "employee_list.json"
KEY_FILE   = "data_key.json"
GY_FILE    = "data_gyoyang.json"
SUD_FILE   = "data_sudong.json"
VEH1_FILE  = "veh1.json"
VEH2_FILE  = "veh2.json"
PREV_FILE  = "ì „ì¼ê·¼ë¬´.json"
COURSE_FILE= "course_result.json"

default_key = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ì„±ì—°","ê¹€ì§€ì€","ì•ˆìœ ë¯¸","ìœ¤ì—¬í—Œ","ìœ¤ì›ì‹¤","ì´ë‚˜ë˜","ì´í˜¸ì„","ì¡°ìœ¤ì˜","ì¡°ì •ë˜"]
default_gy  = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ë³‘ìš±","ê¹€ì„±ì—°","ê¹€ì£¼í˜„","ê¹€ì§€ì€","ì•ˆìœ ë¯¸","ì´í˜¸ì„","ì¡°ì •ë˜"]
default_sd  = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ì„±ì—°","ê¹€ì£¼í˜„","ì´í˜¸ì„","ì¡°ì •ë˜"]
default_veh1= ["2í˜¸ ì¡°ì •ë˜","5í˜¸ ê¶Œí•œì†”","7í˜¸ ê¹€ë‚¨ê· ","8í˜¸ ì´í˜¸ì„","9í˜¸ ê¹€ì£¼í˜„","10í˜¸ ê¹€ì„±ì—°"]
default_veh2= ["4í˜¸ ê¹€ë‚¨ê· ","5í˜¸ ê¹€ë³‘ìš±","6í˜¸ ê¹€ì§€ì€","12í˜¸ ì•ˆìœ ë¯¸","14í˜¸ ê¹€ë©´ì •","15í˜¸ ì´í˜¸ì„","17í˜¸ ê¹€ì„±ì—°","18í˜¸ ê¶Œí•œì†”","19í˜¸ ê¹€ì£¼í˜„","22í˜¸ ì¡°ì •ë˜"]
default_emp = sorted(list({*default_key, *default_gy, *default_sd, "ê¹€ë³‘ìš±","ê¹€ì£¼í˜„"}))

# JSON ë¡œë“œ
employee_list = load_json(EMP_FILE, default_emp)
key_order     = load_json(KEY_FILE,  default_key)
gyoyang_ord   = load_json(GY_FILE,   default_gy)
sudong_ord    = load_json(SUD_FILE,  default_sd)
veh1_lines    = load_json(VEH1_FILE, default_veh1)
veh2_lines    = load_json(VEH2_FILE, default_veh2)

# =====================================
# ì‚¬ì´ë“œë°”: ë°ì´í„° ê´€ë¦¬
# =====================================
st.sidebar.header("ê·¼ë¬´ ë°ì´í„° ê´€ë¦¬")

with st.sidebar.expander("ğŸ‘¥ ì „ì²´ ê·¼ë¬´ìëª…ë‹¨", expanded=False):
    emp_edit = st.text_area("ì „ì²´ ê·¼ë¬´ì", "\n".join(employee_list), height=180)
    if st.button("ğŸ’¾ ê·¼ë¬´ìëª…ë‹¨ ì €ì¥"):
        new_list = [x.strip() for x in emp_edit.splitlines() if x.strip()]
        save_json(EMP_FILE, new_list)
        employee_list = new_list
        st.sidebar.success("ì „ì²´ ê·¼ë¬´ì ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸ”‘ ì—´ì‡  ìˆœë²ˆ", expanded=False):
    key_edit = st.text_area("ì—´ì‡  ìˆœë²ˆ", "\n".join(key_order), height=140)
    if st.button("ğŸ’¾ ì—´ì‡  ì €ì¥"):
        save_json(KEY_FILE, [x.strip() for x in key_edit.splitlines() if x.strip()])
        key_order = load_json(KEY_FILE, default_key)
        st.sidebar.success("ì—´ì‡  ìˆœë²ˆ ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸ“˜ êµì–‘ ìˆœë²ˆ", expanded=False):
    gy_edit = st.text_area("êµì–‘ ìˆœë²ˆ", "\n".join(gyoyang_ord), height=140)
    if st.button("ğŸ’¾ êµì–‘ ì €ì¥"):
        save_json(GY_FILE, [x.strip() for x in gy_edit.splitlines() if x.strip()])
        gyoyang_ord = load_json(GY_FILE, default_gy)
        st.sidebar.success("êµì–‘ ìˆœë²ˆ ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸ§° 1ì¢… ìˆ˜ë™ ìˆœë²ˆ", expanded=False):
    sd_edit = st.text_area("1ì¢… ìˆ˜ë™ ìˆœë²ˆ", "\n".join(sudong_ord), height=140)
    if st.button("ğŸ’¾ 1ì¢… ì €ì¥"):
        save_json(SUD_FILE, [x.strip() for x in sd_edit.splitlines() if x.strip()])
        sudong_ord = load_json(SUD_FILE, default_sd)
        st.sidebar.success("1ì¢… ìˆœë²ˆ ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸš— ì°¨ëŸ‰í‘œ (1ì¢…/2ì¢…)", expanded=False):
    v1_edit = st.text_area("1ì¢… ìˆ˜ë™ ì°¨ëŸ‰í‘œ", "\n".join(veh1_lines), height=110)
    v2_edit = st.text_area("2ì¢… ìë™ ì°¨ëŸ‰í‘œ", "\n".join(veh2_lines), height=150)
    if st.button("ğŸ’¾ ì°¨ëŸ‰í‘œ ì €ì¥"):
        save_json(VEH1_FILE, [x.strip() for x in v1_edit.splitlines() if x.strip()])
        save_json(VEH2_FILE, [x.strip() for x in v2_edit.splitlines() if x.strip()])
        veh1_lines = load_json(VEH1_FILE, default_veh1)
        veh2_lines = load_json(VEH2_FILE, default_veh2)
        st.sidebar.success("ì°¨ëŸ‰í‘œ ì €ì¥ ì™„ë£Œ")

sudong_count = st.sidebar.radio("1ì¢… ìˆ˜ë™ ì¸ì›ìˆ˜", [1, 2], index=0)
repair_cars = [x.strip() for x in st.sidebar.text_input("ì •ë¹„ ì°¨ëŸ‰ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="").split(",") if x.strip()]

prev_data = load_json(PREV_FILE, {"ì—´ì‡ ":"","êµì–‘_5êµì‹œ":"","1ì¢…ìˆ˜ë™":""})
prev_key  = prev_data.get("ì—´ì‡ ","")
prev_gy5  = prev_data.get("êµì–‘_5êµì‹œ","")
prev_sd   = prev_data.get("1ì¢…ìˆ˜ë™","")
st.sidebar.info(f"ì „ì¼ ê¸°ì¤€ â†’ ì—´ì‡ :{prev_key or '-'}, êµì–‘5:{prev_gy5 or '-'}, 1ì¢…:{prev_sd or '-'}")

# =====================================
# GPT OCR
# =====================================
def gpt_extract(img_bytes, want_early=False, want_late=False, want_excluded=False):
    b64 = base64.b64encode(img_bytes).decode()
    user = (
        "ì´ ì´ë¯¸ì§€ëŠ” ìš´ì „ë©´í—ˆì‹œí—˜ ê·¼ë¬´í‘œì…ë‹ˆë‹¤.\n"
        "1) ë„ë¡œì£¼í–‰ ê·¼ë¬´ì ì´ë¦„ë§Œ names ë°°ì—´ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.\n"
        "2) ê´„í˜¸(A-í•©, B-ë¶ˆ ë“±)ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘” ì›ë¬¸ì„ namesì— ë„£ìœ¼ì„¸ìš”.\n"
        "3) íœ´ê°€/êµìœ¡/ì¶œì¥/ê³µê°€/ì—°ê°€/ì—°ì°¨/ëŒë´„ ë“± í‘œê¸°ëœ ì´ë¦„ì€ excludedì— ë„£ìœ¼ì„¸ìš”.\n"
        + ("4) 'ì¡°í‡´:' ìˆìœ¼ë©´ early_leave: [{name, time(ìˆ«ì)}].\n" if want_early else "")
        + ("5) '10ì‹œ ì¶œê·¼'/'ì™¸ì¶œ:' ìˆìœ¼ë©´ late_start: [{name, time(ìˆ«ì)}].\n" if want_late else "")
        + 'JSONë§Œ ë°˜í™˜. ì˜ˆ: {"names":["ê¹€ì„±ì—°(A-í•©)","ì´í˜¸ì„(B-ë¶ˆ)"], "excluded":["ìœ¤ì›ì‹¤"]}'
    )
    try:
        res = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role":"system","content":"í‘œì—ì„œ ì´ë¦„/ì œì™¸ì ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œ"},
                {"role":"user","content":[
                    {"type":"text","text":user},
                    {"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{b64}"}}
                ]}
            ]
        )
        raw = res.choices[0].message.content
        js = json.loads(re.search(r"\{.*\}", raw, re.S).group(0))
        return (
            js.get("names", []),
            js.get("excluded", []),
            js.get("early_leave", []) if want_early else [],
            js.get("late_start", []) if want_late else [],
        )
    except Exception as e:
        st.error(f"OCR ì‹¤íŒ¨: {e}")
        return [], [], [], []

# =====================================
# 1ï¸âƒ£ ì´ë¯¸ì§€ ì—…ë¡œë“œ & OCR
# =====================================
st.markdown("<h4 style='margin-top:6px;'>1ï¸âƒ£ ê·¼ë¬´í‘œ ì´ë¯¸ì§€ ì—…ë¡œë“œ & OCR</h4>", unsafe_allow_html=True)
c1, c2 = st.columns(2)
with c1: m_file = st.file_uploader("ğŸ“¸ ì˜¤ì „ ê·¼ë¬´í‘œ", type=["png","jpg","jpeg"])
with c2: a_file = st.file_uploader("ğŸ“¸ ì˜¤í›„ ê·¼ë¬´í‘œ", type=["png","jpg","jpeg"])

b1, b2 = st.columns(2)
with b1:
    if st.button("ğŸ§  ì˜¤ì „ GPT ì¸ì‹"):
        if not m_file:
            st.warning("ì˜¤ì „ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            with st.spinner("ì˜¤ì „ GPT ë¶„ì„ ì¤‘..."):
                m_names, excluded_auto, _, late = gpt_extract(m_file.read(), want_late=True, want_excluded=True)
                st.session_state.m_names_raw = m_names
                st.session_state.excluded_auto = excluded_auto
                st.session_state.late_start = late
                st.success(f"ì˜¤ì „ ì¸ì‹ â†’ ê·¼ë¬´ì {len(m_names)}ëª…, ì œì™¸ì {len(excluded_auto)}ëª…")

with b2:
    if st.button("ğŸ§  ì˜¤í›„ GPT ì¸ì‹"):
        if not a_file:
            st.warning("ì˜¤í›„ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            with st.spinner("ì˜¤í›„ GPT ë¶„ì„ ì¤‘..."):
                a_names, _, early, _ = gpt_extract(a_file.read(), want_early=True)
                st.session_state.a_names_raw = a_names
                st.session_state.early_leave = early
                st.success(f"ì˜¤í›„ ì¸ì‹ â†’ ê·¼ë¬´ì {len(a_names)}ëª…, ì¡°í‡´ {len(early)}ëª…")

# =====================================
# 2ï¸âƒ£ ì¸ì‹ ê²°ê³¼ í™•ì¸/ìˆ˜ì •
# =====================================
st.markdown("<h6 style='font-size:14px; font-weight:bold; margin-top:10px;'>ê·¼ë¬´ì œì™¸ì</h6>", unsafe_allow_html=True)
excluded_raw = "\n".join(st.session_state.get("excluded_auto", []))
excluded_text = st.text_area("ìë™ì¶”ì¶œ í›„ ìˆ˜ì • ê°€ëŠ¥", excluded_raw, height=100, label_visibility="collapsed")

st.markdown("<h5 style='margin-top:6px;'>ğŸŒ… ì˜¤ì „ ê·¼ë¬´ì (ìˆ˜ì • ê°€ëŠ¥)</h5>", unsafe_allow_html=True)
morning_raw = "\n".join(st.session_state.get("m_names_raw", []))
morning_text = st.text_area("ì˜¤ì „ ê·¼ë¬´ì", morning_raw, height=200)

st.markdown("<h5 style='margin-top:6px;'>ğŸŒ‡ ì˜¤í›„ ê·¼ë¬´ì (ìˆ˜ì • ê°€ëŠ¥)</h5>", unsafe_allow_html=True)
afternoon_raw = "\n".join(st.session_state.get("a_names_raw", []))
afternoon_text = st.text_area("ì˜¤í›„ ê·¼ë¬´ì", afternoon_raw, height=200)

m_list = [x.strip() for x in morning_text.splitlines() if x.strip()]
a_list = [x.strip() for x in afternoon_text.splitlines() if x.strip()]
excluded = {x.strip() for x in excluded_text.splitlines() if x.strip()}

# =====================================
# ìœ í‹¸ í•¨ìˆ˜
# =====================================
def normalize_name(s):
    return re.sub(r"[^ê°€-í£]", "", s or "")

def pick_next_from_cycle(cycle, last, allowed_norms:set):
    if not cycle: return None
    norm = [normalize_name(x) for x in cycle]
    last_norm = normalize_name(last)
    start = (norm.index(last_norm)+1) % len(cycle) if last_norm in norm else 0
    for i in range(len(cycle)*2):
        cand = cycle[(start+i)%len(cycle)]
        if normalize_name(cand) in allowed_norms:
            return cand
    return None

def parse_vehicle_map(lines):
    m = {}
    for l in lines:
        p = l.split()
        if len(p)>=2: m[" ".join(p[1:])] = p[0]
    return m

veh1 = parse_vehicle_map(veh1_lines)
veh2 = parse_vehicle_map(veh2_lines)

def mark_car(car):
    return f"{car} (ì •ë¹„)" if car in repair_cars else car or ""

def get_vehicle(name, vmap):
    n = normalize_name(name)
    for k,v in vmap.items():
        if normalize_name(k)==n:
            return v
    return ""

# =====================================
# 3ï¸âƒ£ ì˜¤ì „ ê·¼ë¬´ ë°°ì •
# =====================================
st.markdown("<h4 style='margin-top:8px;'>3ï¸âƒ£ ì˜¤ì „ ê·¼ë¬´ ë°°ì •</h4>", unsafe_allow_html=True)
if st.button("ğŸ“‹ ì˜¤ì „ ë°°ì • ìƒì„±"):
    try:
        cleaned_m, course_records = split_and_clean_name_list(m_list, employee_list)
        m_list = cleaned_m  # ê´„í˜¸ ì œê±° ë²„ì „ìœ¼ë¡œ ìˆœë²ˆ ë¡œì§ ì‹¤í–‰

        # ğŸ”‘ ì—´ì‡ 
        key_filtered = [x for x in key_order if normalize_name(x) not in {normalize_name(e) for e in excluded}]
        if key_filtered:
            norm = [normalize_name(x) for x in key_filtered]
            prev_norm = normalize_name(prev_key)
            today_key = key_filtered[(norm.index(prev_norm)+1)%len(key_filtered)] if prev_norm in norm else key_filtered[0]
        else:
            today_key = ""
        st.session_state.today_key = today_key

        # ğŸ§‘â€ğŸ« êµì–‘ (ì˜¤ì „)
        gy1 = pick_next_from_cycle(gyoyang_ord, prev_gy5, {normalize_name(x) for x in m_list})
        gy2 = pick_next_from_cycle(gyoyang_ord, gy1 or prev_gy5, {normalize_name(x) for x in m_list}-{normalize_name(gy1)})
        st.session_state.gyoyang_base_for_pm = gy2 or prev_gy5

        # ğŸ”§ 1ì¢… ìˆ˜ë™
        sud_m, last = [], prev_sd
        for _ in range(sudong_count):
            pick = pick_next_from_cycle(sudong_ord, last, {normalize_name(x) for x in m_list}-{normalize_name(x) for x in sud_m})
            if pick: sud_m.append(pick); last = pick
        st.session_state["sudong_base_for_pm"] = sud_m[-1] if sud_m else prev_sd

        # ğŸš— 2ì¢… ìë™
        sud_norms = {normalize_name(x) for x in sud_m}
        auto_m = [x for x in m_list if normalize_name(x) not in sud_norms]

        # ì°¨ëŸ‰ ê¸°ë¡
        st.session_state.morning_assigned_cars_1 = [get_vehicle(x,veh1) for x in sud_m if get_vehicle(x,veh1)]
        st.session_state.morning_assigned_cars_2 = [get_vehicle(x,veh2) for x in auto_m if get_vehicle(x,veh2)]
        st.session_state.morning_auto_names = auto_m + sud_m

        # === ì¶œë ¥ ===
        lines = []
        lines.append(f"ì—´ì‡ : {today_key}")
        if gy1: lines.append(f"1êµì‹œ: {gy1}")
        if gy2: lines.append(f"2êµì‹œ: {gy2}")
        if sud_m:
            for nm in sud_m:
                lines.append(f"1ì¢…ìˆ˜ë™: {nm} {mark_car(get_vehicle(nm,veh1))}")
        else:
            lines.append("1ì¢…ìˆ˜ë™: (ì—†ìŒ)")
        if auto_m:
            lines.append("2ì¢…ìë™:")
            for nm in auto_m:
                lines.append(f" â€¢ {nm} {mark_car(get_vehicle(nm,veh2))}")

        # ğŸ§­ ì½”ìŠ¤ì ê²€ ê²°ê³¼ ì¶œë ¥
        if course_records:
            lines.append("")
            lines.append("ğŸ§­ ì½”ìŠ¤ì ê²€ ê²°ê³¼:")
            for c in ["A","B"]:
                passed = [r["name"] for r in course_records if r["course"]==f"{c}ì½”ìŠ¤" and r["result"]=="í•©ê²©"]
                failed = [r["name"] for r in course_records if r["course"]==f"{c}ì½”ìŠ¤" and r["result"]=="ë¶ˆí•©ê²©"]
                if passed: lines.append(f" â€¢ {c}ì½”ìŠ¤ í•©ê²©: {', '.join(passed)}")
                if failed: lines.append(f" â€¢ {c}ì½”ìŠ¤ ë¶ˆí•©ê²©: {', '.join(failed)}")
            save_json(COURSE_FILE, course_records)

        result_text = "\n".join(lines)
        st.markdown("<h5>ğŸ“‹ ì˜¤ì „ ê²°ê³¼</h5>", unsafe_allow_html=True)
        st.code(result_text, language="text")
        clipboard_copy_button("ğŸ“‹ ê²°ê³¼ ë³µì‚¬í•˜ê¸°", result_text)

    except Exception as e:
        st.error(f"ì˜¤ì „ ì˜¤ë¥˜: {e}")

# =====================================
# 4ï¸âƒ£ ì˜¤í›„ ê·¼ë¬´ ë°°ì •
# =====================================
st.markdown("<h4 style='margin-top:10px;'>4ï¸âƒ£ ì˜¤í›„ ê·¼ë¬´ ë°°ì •</h4>", unsafe_allow_html=True)
save_check = st.checkbox("ì´ ê²°ê³¼ë¥¼ ì „ì¼ ê¸°ì¤€ìœ¼ë¡œ ì €ì¥", value=True)

if st.button("ğŸ“‹ ì˜¤í›„ ë°°ì • ìƒì„±"):
    try:
        today_key = st.session_state.get("today_key", prev_key)
        gy_start = st.session_state.get("gyoyang_base_for_pm", prev_gy5)
        sud_base = st.session_state.get("sudong_base_for_pm", prev_sd)

        # ğŸ§‘â€ğŸ« ì˜¤í›„ êµì–‘
        used=set(); gy3=gy4=gy5=None
        for p in [3,4,5]:
            pick = pick_next_from_cycle(gyoyang_ord, gy_start if p==3 else locals()[f"gy{p-1}"], {normalize_name(x) for x in a_list}-used)
            if pick:
                locals()[f"gy{p}"]=pick
                used.add(normalize_name(pick))

        # ğŸ”§ 1ì¢… ìˆ˜ë™ (ì˜¤í›„)
        sud_a, last = [], sud_base
        for _ in range(sudong_count):
            pick = pick_next_from_cycle(sudong_ord, last, {normalize_name(x) for x in a_list})
            if pick: sud_a.append(pick); last=pick
        used.update(normalize_name(x) for x in sud_a)

        # ğŸš— 2ì¢… ìë™
        sud_norms = {normalize_name(x) for x in sud_a}
        auto_a = [x for x in a_list if normalize_name(x) not in sud_norms]

        # === ì¶œë ¥ ===
        lines=[]
        lines.append(f"ì—´ì‡ : {today_key}")
        if gy3: lines.append(f"3êµì‹œ: {gy3}")
        if gy4: lines.append(f"4êµì‹œ: {gy4}")
        if gy5: lines.append(f"5êµì‹œ: {gy5}")
        if sud_a:
            for nm in sud_a: lines.append(f"1ì¢…ìˆ˜ë™: {nm} {mark_car(get_vehicle(nm,veh1))}")
        else: lines.append("1ì¢…ìˆ˜ë™: (ì—†ìŒ)")
        if auto_a:
            lines.append("2ì¢…ìë™:")
            for nm in auto_a:
                lines.append(f" â€¢ {nm} {mark_car(get_vehicle(nm,veh2))}")

        # ì˜¤ì „ ëŒ€ë¹„ ë¹„êµ
        lines.append("")
        lines.append("ğŸ§¾ ì˜¤ì „ ëŒ€ë¹„ ë¹„êµ:")
        morning_set = set(st.session_state.get("morning_auto_names", []))
        afternoon_set = set(auto_a)
        added = sorted(list(afternoon_set - morning_set))
        removed = sorted(list(morning_set - afternoon_set))
        if added: lines.append(" â€¢ ìƒˆ ë„ë¡œì£¼í–‰ ì¸ì›: " + ", ".join(added))
        if removed: lines.append(" â€¢ ë¹ ì§„ ì¸ì›: " + ", ".join(removed))

        result_text = "\n".join(lines)
        st.markdown("<h5>ğŸ“‹ ì˜¤í›„ ê²°ê³¼</h5>", unsafe_allow_html=True)
        st.code(result_text, language="text")
        clipboard_copy_button("ğŸ“‹ ê²°ê³¼ ë³µì‚¬í•˜ê¸°", result_text)

        # âœ… ì „ì¼ ì €ì¥
        if save_check:
            save_json(PREV_FILE, {
                "ì—´ì‡ ": today_key,
                "êµì–‘_5êµì‹œ": gy5 or gy4 or gy3 or prev_gy5,
                "1ì¢…ìˆ˜ë™": sud_a[-1] if sud_a else prev_sd
            })
            st.success("ì „ì¼ê·¼ë¬´.json ì—…ë°ì´íŠ¸ ì™„ë£Œ")

    except Exception as e:
        st.error(f"ì˜¤í›„ ì˜¤ë¥˜: {e}")
