# app.py â€” ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì • v7.17 (ìëª¨+ì´ˆì„± êµì • ê°•í™” ì™„ì „ë³¸)
import streamlit as st
from openai import OpenAI
import base64, re, json, os

# =====================================
# í˜ì´ì§€ ì„¤ì •
# =====================================
st.set_page_config(page_title="ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì •", layout="wide")
st.markdown("<h3 style='text-align:center; font-size:22px;'>ğŸš— ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì • v7.17</h3>", unsafe_allow_html=True)

# =====================================
# OpenAI ì´ˆê¸°í™”
# =====================================
try:
    client = OpenAI(api_key=st.secrets["general"]["OPENAI_API_KEY"])
except Exception:
    st.error("âš ï¸ OPENAI_API_KEY ì„¤ì • í•„ìš”")
    st.stop()
MODEL_NAME = "gpt-4o"

# =====================================
# íŒŒì¼ ê²½ë¡œ
# =====================================
KEY_FILE = "data_key.json"
GY_FILE = "data_gyoyang.json"
SUD_FILE = "data_sudong.json"
VEH1_FILE = "veh1.json"
VEH2_FILE = "veh2.json"
EMP_FILE = "employee_list.json"
PREV_FILE = "ì „ì¼ê·¼ë¬´.json"
COURSE_FILE = "course_check.json"

# =====================================
# íŒŒì¼ IO í•¨ìˆ˜
# =====================================
def load_json(path, default):
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return default

def save_json(path, data):
    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# =====================================
# ë¬¸ìì—´ ìœ í‹¸
# =====================================
def normalize_name(s):
    return re.sub(r"[^ê°€-í£]", "", re.sub(r"\(.*?\)", "", s or ""))

# =====================================
# ë³µì‚¬ ë²„íŠ¼ (JS)
# =====================================
def clipboard_copy_button(label, text):
    btn = st.button(label, key=f"copy_{hash(text)}")
    if btn:
        st.markdown(
            f"""
            <script>
            navigator.clipboard.writeText(`{text}`);
            alert("ê²°ê³¼ê°€ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!");
            </script>
            """,
            unsafe_allow_html=True
        )

# =====================================
# OCR êµì • ì•Œê³ ë¦¬ì¦˜ (ìëª¨+ì´ˆì„± í˜¼í•©)
# =====================================
def split_hangul(ch):
    """í•œê¸€ ì´ˆì„±/ì¤‘ì„±/ì¢…ì„± ë¶„ë¦¬"""
    base = ord(ch) - 0xAC00
    cho = base // 588
    jung = (base % 588) // 28
    jong = base % 28
    return cho, jung, jong

CHO_LIST = [chr(c) for c in range(ord('ã„±'), ord('ã…')+1)]

def hangul_similarity(a, b):
    """ìëª¨ ë‹¨ìœ„ ìœ ì‚¬ë„ (0~1)"""
    if not a or not b: return 0
    score = 0
    total = max(len(a), len(b))
    for i in range(min(len(a), len(b))):
        ca, cb = a[i], b[i]
        if not ('ê°€' <= ca <= 'í£' and 'ê°€' <= cb <= 'í£'):
            score += (1 if ca == cb else 0)
            continue
        try:
            cho_a, jung_a, jong_a = split_hangul(ca)
            cho_b, jung_b, jong_b = split_hangul(cb)
        except:
            continue
        s = 0
        if cho_a == cho_b: s += 0.4
        if jung_a == jung_b: s += 0.4
        if jong_a == jong_b: s += 0.2
        score += s
    return round(score / total, 3)

def cho_similarity(a, b):
    """ì´ˆì„± ì¼ì¹˜ìœ¨"""
    def get_initials(word):
        res = []
        for ch in word:
            if 'ê°€' <= ch <= 'í£':
                cho, _, _ = split_hangul(ch)
                res.append(CHO_LIST[cho])
        return ''.join(res)
    ia, ib = get_initials(a), get_initials(b)
    return sum(1 for x, y in zip(ia, ib) if x == y) / max(len(ia), len(ib), 1)

def combined_similarity(a, b):
    """ìëª¨ 60% + ì´ˆì„± 40% í˜¼í•©"""
    return 0.6 * hangul_similarity(a, b) + 0.4 * cho_similarity(a, b)

def correct_name(name, ref_list, norm_to_original=None, initials_to_names=None):
    """OCR ê²°ê³¼ ì´ë¦„ â†’ ê·¼ë¬´ìëª…ë‹¨ ê¸°ë°˜ êµì •"""
    if not name: return name
    norm_name = normalize_name(name)
    best_match, best_score = name, 0
    for ref in ref_list:
        score = combined_similarity(norm_name, ref)
        if score > best_score:
            best_score = score
            best_match = ref
    if best_score >= 0.75 and best_match != name:
        return best_match
    return name

# =====================================
# ì‚¬ì´ë“œë°” ì…ë ¥
# =====================================
st.sidebar.header("ìˆœë²ˆí‘œ / ì°¨ëŸ‰í‘œ / ì˜µì…˜")

def _list(s): return [x.strip() for x in s.splitlines() if x.strip()]

# ê¸°ë³¸ê°’ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ì´ˆê¸° ë°ì´í„°)
default_key = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ì„±ì—°","ê¹€ì§€ì€","ì•ˆìœ ë¯¸","ìœ¤ì—¬í—Œ","ìœ¤ì›ì‹¤","ì´ë‚˜ë˜","ì´í˜¸ì„","ì¡°ìœ¤ì˜","ì¡°ì •ë˜"]
default_gy = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ë³‘ìš±","ê¹€ì„±ì—°","ê¹€ì£¼í˜„","ê¹€ì§€ì€","ì•ˆìœ ë¯¸","ì´í˜¸ì„","ì¡°ì •ë˜"]
default_sd = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ì„±ì—°","ê¹€ì£¼í˜„","ì´í˜¸ì„","ì¡°ì •ë˜"]
default_veh1 = ["2í˜¸ ì¡°ì •ë˜","5í˜¸ ê¶Œí•œì†”","7í˜¸ ê¹€ë‚¨ê· ","8í˜¸ ì´í˜¸ì„","9í˜¸ ê¹€ì£¼í˜„","10í˜¸ ê¹€ì„±ì—°"]
default_veh2 = ["4í˜¸ ê¹€ë‚¨ê· ","5í˜¸ ê¹€ë³‘ìš±","6í˜¸ ê¹€ì§€ì€","12í˜¸ ì•ˆìœ ë¯¸","14í˜¸ ê¹€ë©´ì •","15í˜¸ ì´í˜¸ì„","17í˜¸ ê¹€ì„±ì—°","18í˜¸ ê¶Œí•œì†”","19í˜¸ ê¹€ì£¼í˜„","22í˜¸ ì¡°ì •ë˜"]
default_emp = list({*default_key, *default_gy, *default_sd})

# íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
key_order = load_json(KEY_FILE, default_key)
gyoyang_order = load_json(GY_FILE, default_gy)
sudong_order = load_json(SUD_FILE, default_sd)
veh1_lines = load_json(VEH1_FILE, default_veh1)
veh2_lines = load_json(VEH2_FILE, default_veh2)
employee_list = load_json(EMP_FILE, default_emp)

# ì‚¬ì´ë“œë°” êµ¬ì„± (ê¸°ë³¸ ìˆ¨ê¹€)
with st.sidebar.expander("ğŸ”‘ ì—´ì‡  ìˆœë²ˆ", expanded=False):
    key_edit = st.text_area("ì—´ì‡  ìˆœë²ˆ", "\n".join(key_order), height=150)
    if st.button("ğŸ’¾ ì—´ì‡  ì €ì¥"):
        save_json(KEY_FILE, _list(key_edit))
        st.sidebar.success("ì—´ì‡  ìˆœë²ˆ ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸ“˜ êµì–‘ ìˆœë²ˆ", expanded=False):
    gy_edit = st.text_area("êµì–‘ ìˆœë²ˆ", "\n".join(gyoyang_order), height=150)
    if st.button("ğŸ’¾ êµì–‘ ì €ì¥"):
        save_json(GY_FILE, _list(gy_edit))
        st.sidebar.success("êµì–‘ ìˆœë²ˆ ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸ§° 1ì¢… ìˆ˜ë™ ìˆœë²ˆ", expanded=False):
    sd_edit = st.text_area("1ì¢… ìˆ˜ë™ ìˆœë²ˆ", "\n".join(sudong_order), height=150)
    if st.button("ğŸ’¾ 1ì¢… ì €ì¥"):
        save_json(SUD_FILE, _list(sd_edit))
        st.sidebar.success("1ì¢… ìˆœë²ˆ ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸš— ì°¨ëŸ‰í‘œ", expanded=False):
    v1_edit = st.text_area("1ì¢… ìˆ˜ë™", "\n".join(veh1_lines), height=120)
    v2_edit = st.text_area("2ì¢… ìë™", "\n".join(veh2_lines), height=160)
    if st.button("ğŸ’¾ ì°¨ëŸ‰í‘œ ì €ì¥"):
        save_json(VEH1_FILE, _list(v1_edit))
        save_json(VEH2_FILE, _list(v2_edit))
        st.sidebar.success("ì°¨ëŸ‰í‘œ ì €ì¥ ì™„ë£Œ")

sudong_count = st.sidebar.radio("1ì¢… ìˆ˜ë™ ì¸ì›ìˆ˜", [1, 2], index=0)
repair_cars = [x.strip() for x in st.sidebar.text_input("ì •ë¹„ ì°¨ëŸ‰ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="").split(",") if x.strip()]

# ì „ì¼ê·¼ë¬´ ë¶ˆëŸ¬ì˜¤ê¸°
prev_data = load_json(PREV_FILE, {"ì—´ì‡ ":"","êµì–‘_5êµì‹œ":"","1ì¢…ìˆ˜ë™":""})
prev_key = prev_data.get("ì—´ì‡ ","")
prev_gy5 = prev_data.get("êµì–‘_5êµì‹œ","")
prev_sd = prev_data.get("1ì¢…ìˆ˜ë™","")
st.sidebar.markdown("---")
st.sidebar.info(f"ì „ì¼ ê¸°ì¤€ â†’ ì—´ì‡ :{prev_key or '-'}, êµì–‘5:{prev_gy5 or '-'}, 1ì¢…:{prev_sd or '-'}")

# =====================================
# GPT OCR (ê·¼ë¬´ì œì™¸ì ìë™ì¶”ì¶œ í¬í•¨)
# =====================================
def gpt_extract(img_bytes, want_early=False, want_late=False, want_excluded=False):
    b64 = base64.b64encode(img_bytes).decode()
    user = (
        "ì´ ì´ë¯¸ì§€ëŠ” ìš´ì „ë©´í—ˆì‹œí—˜ ê·¼ë¬´í‘œì…ë‹ˆë‹¤.\n"
        "1) ë„ë¡œì£¼í–‰ ê·¼ë¬´ì ì´ë¦„ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.\n"
        "2) ê´„í˜¸ ì•ˆì˜ ì •ë³´(A-í•©, B-ë¶ˆ ë“±)ëŠ” ìœ ì§€í•˜ì„¸ìš”.\n"
        "3) 'íœ´ê°€, êµìœ¡, ì¶œì¥, ê³µê°€, ì—°ê°€, ì—°ì°¨, ëŒë´„' ë“±ì˜ í‘œê¸°ê°€ ìˆìœ¼ë©´ 'excluded'ì— ì´ë¦„ì„ ë„£ìœ¼ì„¸ìš”.\n"
        + ("4) 'ì¡°í‡´:'ê°€ ìˆë‹¤ë©´ ì´ë¦„ê³¼ ì‹œê°„ì„ ìˆ«ì(ì˜ˆ:14, 14.5)ë¡œ JSONì— í¬í•¨.\n" if want_early else "")
        + ("5) '10ì‹œ ì¶œê·¼' ë˜ëŠ” 'ì™¸ì¶œ:' í•­ëª©ì´ ìˆë‹¤ë©´ ì´ë¦„ê³¼ ì‹œê°„ì„ ìˆ«ì(ì˜ˆ:10)ë¡œ JSONì— í¬í•¨.\n" if want_late else "")
        + "ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜.\n"
        "ì˜ˆì‹œ: {\"names\": [\"ê¹€ì„±ì—°(A-í•©)\",\"ì´í˜¸ì„(B-ë¶ˆ)\"],"
        "\"excluded\": [\"ìœ¤ì›ì‹¤\"],"
        "\"early_leave\": [{\"name\":\"ê¹€ë³‘ìš±\",\"time\":14}],"
        "\"late_start\": [{\"name\":\"ì•ˆìœ ë¯¸\",\"time\":10}]}"
    )
    try:
        res = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role":"system","content":"í‘œì—ì„œ ì´ë¦„ì„ JSONìœ¼ë¡œ ì¶”ì¶œ"},
                {"role":"user","content":[
                    {"type":"text","text":user},
                    {"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{b64}"}}
                ]}
            ]
        )
        raw = res.choices[0].message.content
        js = json.loads(re.search(r"\{.*\}", raw, re.S).group(0))
        names = js.get("names", [])
        excluded = js.get("excluded", [])
        early = js.get("early_leave", []) if want_early else []
        late = js.get("late_start", []) if want_late else []
        return names, excluded, early, late
    except Exception as e:
        st.error(f"OCR ì‹¤íŒ¨: {e}")
        return [], [], [], []

# =====================================
# 1ï¸âƒ£ ì´ë¯¸ì§€ ì—…ë¡œë“œ & OCR
# =====================================
st.markdown("<h4>1ï¸âƒ£ ê·¼ë¬´í‘œ ì´ë¯¸ì§€ ì—…ë¡œë“œ & OCR</h4>", unsafe_allow_html=True)
col1, col2 = st.columns(2)
with col1: m_file = st.file_uploader("ğŸ“¸ ì˜¤ì „ ê·¼ë¬´í‘œ", type=["png","jpg","jpeg"])
with col2: a_file = st.file_uploader("ğŸ“¸ ì˜¤í›„ ê·¼ë¬´í‘œ", type=["png","jpg","jpeg"])

if st.button("ğŸ§  ì˜¤ì „ GPT ì¸ì‹"):
    if not m_file: st.warning("ì˜¤ì „ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        with st.spinner("ì˜¤ì „ GPT ë¶„ì„ ì¤‘..."):
            m_names, excluded, _, late = gpt_extract(m_file.read(), want_late=True, want_excluded=True)
            st.session_state.m_names_raw = m_names
            st.session_state.excluded_auto = excluded
            st.session_state.late_start = late
            st.success(f"ì˜¤ì „ ì¸ì‹ ì™„ë£Œ: ê·¼ë¬´ì {len(m_names)}ëª…, ì œì™¸ì {len(excluded)}ëª…")

if st.button("ğŸ§  ì˜¤í›„ GPT ì¸ì‹"):
    if not a_file: st.warning("ì˜¤í›„ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        with st.spinner("ì˜¤í›„ GPT ë¶„ì„ ì¤‘..."):
            a_names, _, early, _ = gpt_extract(a_file.read(), want_early=True)
            st.session_state.a_names_raw = a_names
            st.session_state.early_leave = early
            st.success(f"ì˜¤í›„ ì¸ì‹ ì™„ë£Œ: ê·¼ë¬´ì {len(a_names)}ëª…, ì¡°í‡´ {len(early)}ëª…")

# =====================================
# 2ï¸âƒ£ ì¸ì‹ ê²°ê³¼ í™•ì¸ (ìŠ¤í¬ë¡¤ ì ìš©)
# =====================================
st.markdown("### ğŸš« ê·¼ë¬´ì œì™¸ì (ìë™ì¶”ì¶œ í›„ ìˆ˜ì • ê°€ëŠ¥)")
excluded_raw = "\n".join(st.session_state.get("excluded_auto", []))
excluded_text = st.text_area("ê·¼ë¬´ì œì™¸ì", excluded_raw, height=120)

st.markdown("### ğŸŒ… ì˜¤ì „ ê·¼ë¬´ì (ìˆ˜ì • ê°€ëŠ¥)")
morning_raw = "\n".join(st.session_state.get("m_names_raw", []))
morning_text = st.text_area("ì˜¤ì „ ê·¼ë¬´ì", morning_raw, height=220)

st.markdown("### ğŸŒ‡ ì˜¤í›„ ê·¼ë¬´ì (ìˆ˜ì • ê°€ëŠ¥)")
afternoon_raw = "\n".join(st.session_state.get("a_names_raw", []))
afternoon_text = st.text_area("ì˜¤í›„ ê·¼ë¬´ì", afternoon_raw, height=220)

m_list = [x.strip() for x in morning_text.splitlines() if x.strip()]
a_list = [x.strip() for x in afternoon_text.splitlines() if x.strip()]
excluded = {x.strip() for x in excluded_text.splitlines() if x.strip()}

# =====================================
# ë°°ì • ë³´ì¡° ìœ í‹¸
# =====================================
def parse_vehicle_map(lines):
    m = {}
    for line in lines:
        parts = line.strip().split()
        if len(parts) >= 2:
            car = parts[0]
            name = " ".join(parts[1:])
            m[name] = car
    return m

def get_vehicle(name, veh_map):
    nkey = normalize_name(name)
    for k, v in veh_map.items():
        if normalize_name(k) == nkey:
            return v
    return ""

def mark_car(car, repair_list):
    return f"{car}{' (ì •ë¹„)' if (car and car in repair_list) else ''}" if car else ""

def pick_next_from_cycle(cycle, last, allowed_norms: set):
    """ìˆœë²ˆ ìˆœí™˜ ì„ íƒ (allowed_norms: ì¶œê·¼/ì œì™¸ ë°˜ì˜ëœ í—ˆìš©ì ì§‘í•©; ì •ê·œí™” ê¸°ì¤€)"""
    if not cycle:
        return None
    cyc_norm = [normalize_name(x) for x in cycle]
    last_norm = normalize_name(last)
    start = (cyc_norm.index(last_norm) + 1) % len(cycle) if last_norm in cyc_norm else 0
    for i in range(len(cycle)*2):
        cand = cycle[(start + i) % len(cycle)]
        if normalize_name(cand) in allowed_norms:
            return cand
    return None

def extract_course_from_token(token: str):
    """
    ì´ë¦„ í† í° ë‚´ ê´„í˜¸ì—ì„œ ì½”ìŠ¤/í•©ë¶ˆ ì¶”ì¶œ.
    - íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ 'A' ë˜ëŠ” 'B'ë§Œ ì¸ì‹, 'í•©'/'ë¶ˆ'ë¡œ ê²°ê³¼ íŒë‹¨.
    - ì˜ˆ: '(A-í•©)', '(Aí•©)', '(B ë¶ˆ)' ë“± â†’ ('A', 'í•©ê²©') / ('B', 'ë¶ˆí•©ê²©')
    """
    m = re.search(r"\((.*?)\)", token)
    if not m:
        return None
    raw = m.group(1)
    up = re.sub(r"[^A-Za-zê°€-í£]", "", raw).upper()  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    course = 'A' if 'A' in up else ('B' if 'B' in up else None)
    result = 'í•©ê²©' if 'í•©' in up else ('ë¶ˆí•©ê²©' if 'ë¶ˆ' in up else None)
    if course and result:
        return course, result
    return None

# =====================================
# 3ï¸âƒ£ ì˜¤ì „ ë°°ì •
# =====================================
st.markdown("---")
st.markdown("## 3ï¸âƒ£ ì˜¤ì „ ê·¼ë¬´ ë°°ì •")

if st.button("ğŸ“‹ ì˜¤ì „ ë°°ì • ìƒì„±"):
    try:
        # ì°¨ëŸ‰í‘œ ë§¤í•‘
        veh1_map = parse_vehicle_map(veh1_lines)
        veh2_map = parse_vehicle_map(veh2_lines)

        # OCR â†’ êµì • â†’ ì½”ìŠ¤ ì¶”ì¶œ
        corrected_m = [correct_name(x, employee_list) for x in m_list]
        course_records = []
        cleaned_m = []
        for token in corrected_m:
            # ì´ë¦„ê³¼ ì½”ìŠ¤ ë¶„ë¦¬
            info = extract_course_from_token(token)
            pure = re.sub(r"\(.*?\)", "", token).strip()
            if info:
                c, r = info
                course_records.append({"name": pure, "course": f"{c}ì½”ìŠ¤", "result": r})
            cleaned_m.append(pure)
        # ì½”ìŠ¤ ê²°ê³¼ ì €ì¥ (ì˜¤ì „ ì¶œë ¥ìš©)
        save_json(COURSE_FILE, course_records)

        # ì œì™¸ ë°˜ì˜
        excl_norms = {normalize_name(x) for x in excluded}
        m_norms = {normalize_name(x) for x in cleaned_m} - excl_norms

        # ğŸ”‘ ì—´ì‡ (ì „ì¼ ì´í›„ ìˆœë²ˆ)
        filtered_keys = [x for x in key_order if normalize_name(x) not in excl_norms]
        if filtered_keys:
            knorms = [normalize_name(x) for x in filtered_keys]
            pnorm = normalize_name(prev_key)
            today_key = filtered_keys[(knorms.index(pnorm)+1) % len(filtered_keys)] if pnorm in knorms else filtered_keys[0]
        else:
            today_key = ""

        # ğŸ§‘â€ğŸ« ì˜¤ì „ êµì–‘ 1Â·2êµì‹œ
        gy1 = pick_next_from_cycle(gyoyang_order, prev_gy5, m_norms)
        gy1_norm = normalize_name(gy1) if gy1 else None
        gy2 = pick_next_from_cycle(gyoyang_order, (gy1 or prev_gy5), m_norms - ({gy1_norm} if gy1_norm else set()))

        # ğŸ”§ 1ì¢… ìˆ˜ë™
        sud_m, last_pick = [], prev_sd
        for _ in range(sudong_count):
            cand = pick_next_from_cycle(sudong_order, last_pick, m_norms - {normalize_name(x) for x in sud_m})
            if not cand:
                break
            sud_m.append(cand)
            last_pick = cand

        # ğŸš— 2ì¢… ìë™ = ì˜¤ì „ ì „ì²´ - 1ì¢…
        sud_norms_m = {normalize_name(x) for x in sud_m}
        auto_m = [nm for nm in cleaned_m if normalize_name(nm) in (m_norms - sud_norms_m)]

        # ìƒíƒœ ì €ì¥ (ì˜¤ì „ ëŒ€ë¹„/ì°¨ëŸ‰ ë¹„êµìš©)
        st.session_state["today_key"] = today_key
        st.session_state["am_gy_base_for_pm"] = gy2 or gy1 or prev_gy5
        st.session_state["am_sud_base_for_pm"] = (sud_m[-1] if sud_m else prev_sd)

        st.session_state["am_driver_names"] = sud_m + auto_m
        st.session_state["am_cars_1"] = [get_vehicle(x, veh1_map) for x in sud_m if get_vehicle(x, veh1_map)]
        st.session_state["am_cars_2"] = [get_vehicle(x, veh2_map) for x in auto_m if get_vehicle(x, veh2_map)]

        # === ì¶œë ¥
        lines = []
        if today_key: lines.append(f"ì—´ì‡ : {today_key}")
        if gy1: lines.append(f"1êµì‹œ(êµì–‘): {gy1}")
        if gy2: lines.append(f"2êµì‹œ(êµì–‘): {gy2}")

        if sud_m:
            for nm in sud_m:
                lines.append(f"1ì¢…ìˆ˜ë™: {nm} {mark_car(get_vehicle(nm, veh1_map), repair_cars)}")
            if sudong_count == 2 and len(sud_m) < 2:
                lines.append("â€» ìˆ˜ë™ ê°€ëŠ¥ ì¸ì›ì´ 1ëª…ì…ë‹ˆë‹¤.")
        else:
            lines.append("1ì¢…ìˆ˜ë™: (ë°°ì •ì ì—†ìŒ)")

        if auto_m:
            lines.append("2ì¢… ìë™:")
            for nm in auto_m:
                lines.append(f" â€¢ {nm} {mark_car(get_vehicle(nm, veh2_map), repair_cars)}")
        else:
            lines.append("2ì¢… ìë™: (ë°°ì •ì ì—†ìŒ)")

        # ğŸ§­ ì½”ìŠ¤ì ê²€ ê²°ê³¼(ì˜¤ì „ë§Œ)
        if course_records:
            lines.append("")
            lines.append("ğŸ§­ ì½”ìŠ¤ì ê²€ ê²°ê³¼:")
            a_pass = [c["name"] for c in course_records if c["course"]=="Aì½”ìŠ¤" and c["result"]=="í•©ê²©"]
            a_fail = [c["name"] for c in course_records if c["course"]=="Aì½”ìŠ¤" and c["result"]=="ë¶ˆí•©ê²©"]
            b_pass = [c["name"] for c in course_records if c["course"]=="Bì½”ìŠ¤" and c["result"]=="í•©ê²©"]
            b_fail = [c["name"] for c in course_records if c["course"]=="Bì½”ìŠ¤" and c["result"]=="ë¶ˆí•©ê²©"]
            if a_pass: lines.append(" â€¢ Aì½”ìŠ¤ í•©ê²©: " + ", ".join(a_pass))
            if a_fail: lines.append(" â€¢ Aì½”ìŠ¤ ë¶ˆí•©ê²©: " + ", ".join(a_fail))
            if b_pass: lines.append(" â€¢ Bì½”ìŠ¤ í•©ê²©: " + ", ".join(b_pass))
            if b_fail: lines.append(" â€¢ Bì½”ìŠ¤ ë¶ˆí•©ê²©: " + ", ".join(b_fail))

        result_text = "\n".join(lines)
        st.markdown("### ğŸ“‹ ì˜¤ì „ ê²°ê³¼")
        st.code(result_text, language="text")
        clipboard_copy_button("ğŸ“‹ ê²°ê³¼ ë³µì‚¬í•˜ê¸°", result_text)

    except Exception as e:
        st.error(f"ì˜¤ì „ ì˜¤ë¥˜: {e}")

# =====================================
# 4ï¸âƒ£ ì˜¤í›„ ë°°ì • (+ì˜¤ì „ ëŒ€ë¹„ ë¹„êµ/ë¯¸ë°°ì •/ì €ì¥)
# =====================================
st.markdown("---")
st.markdown("## 4ï¸âƒ£ ì˜¤í›„ ê·¼ë¬´ ë°°ì •")

save_check = st.checkbox("ì´ ê²°ê³¼ë¥¼ ì „ì¼ê·¼ë¬´.jsonìœ¼ë¡œ ì €ì¥", value=True)

if st.button("ğŸ“‹ ì˜¤í›„ ë°°ì • ìƒì„±"):
    try:
        veh1_map = parse_vehicle_map(veh1_lines)
        veh2_map = parse_vehicle_map(veh2_lines)

        # êµì •
        corrected_a = [correct_name(x, employee_list) for x in a_list]
        excl_norms = {normalize_name(x) for x in excluded}
        a_norms = {normalize_name(x) for x in corrected_a} - excl_norms

        # ì˜¤í›„ êµì–‘ 3Â·4Â·5
        gy_start = st.session_state.get("am_gy_base_for_pm", prev_gy5)
        used = set()
        gy3 = pick_next_from_cycle(gyoyang_order, gy_start, a_norms)
        if gy3: used.add(normalize_name(gy3))
        gy4 = pick_next_from_cycle(gyoyang_order, gy3 or gy_start, a_norms - used)
        if gy4: used.add(normalize_name(gy4))
        gy5 = pick_next_from_cycle(gyoyang_order, gy4 or gy3 or gy_start, a_norms - used)

        # ì˜¤í›„ 1ì¢… ìˆ˜ë™ (êµì–‘ê³¼ ì¤‘ë³µ í—ˆìš©)
        sud_base = st.session_state.get("am_sud_base_for_pm", prev_sd)
        sud_a, last_pick = [], sud_base
        for _ in range(sudong_count):
            cand = pick_next_from_cycle(sudong_order, last_pick, a_norms)
            if not cand:
                break
            sud_a.append(cand)
            last_pick = cand

        # ì˜¤í›„ 2ì¢… ìë™ = ì˜¤í›„ ì „ì²´ - 1ì¢…
        sud_norms_a = {normalize_name(x) for x in sud_a}
        auto_a = [nm for nm in corrected_a if normalize_name(nm) in (a_norms - sud_norms_a)]

        # === ì¶œë ¥
        today_key = st.session_state.get("today_key", prev_key)
        lines = []
        if today_key: lines.append(f"ì—´ì‡ : {today_key}")
        if gy3: lines.append(f"3êµì‹œ(êµì–‘): {gy3}")
        if gy4: lines.append(f"4êµì‹œ(êµì–‘): {gy4}")
        if gy5: lines.append(f"5êµì‹œ(êµì–‘): {gy5}")

        if sud_a:
            for nm in sud_a:
                lines.append(f"1ì¢…ìˆ˜ë™: {nm} {mark_car(get_vehicle(nm, veh1_map), repair_cars)}")
            if sudong_count == 2 and len(sud_a) < 2:
                lines.append("â€» ìˆ˜ë™ ê°€ëŠ¥ ì¸ì›ì´ 1ëª…ì…ë‹ˆë‹¤.")
        else:
            lines.append("1ì¢…ìˆ˜ë™: (ë°°ì •ì ì—†ìŒ)")

        if auto_a:
            lines.append("2ì¢… ìë™:")
            for nm in auto_a:
                lines.append(f" â€¢ {nm} {mark_car(get_vehicle(nm, veh2_map), repair_cars)}")
        else:
            lines.append("2ì¢… ìë™: (ë°°ì •ì ì—†ìŒ)")

        # === ì˜¤ì „ ëŒ€ë¹„ ë¹„êµ (ì‹ ê·œ íˆ¬ì… / ë¹ ì§„ ì¸ì›)
        lines.append("")
        lines.append("ì˜¤ì „ ëŒ€ë¹„ ë¹„êµ:")

        am_drivers = st.session_state.get("am_driver_names", [])  # ì˜¤ì „ ìš´ì „ ì „ì²´(1+2)
        am_norms = {normalize_name(x) for x in am_drivers}
        pm_drivers = sud_a + auto_a
        pm_norms = {normalize_name(x) for x in pm_drivers}

        new_joiners = sorted([nm for nm in pm_drivers if normalize_name(nm) not in am_norms])
        missing = sorted([nm for nm in am_drivers if normalize_name(nm) not in pm_norms])

        if new_joiners:
            lines.append(" â€¢ ì‹ ê·œ íˆ¬ì…: " + ", ".join(new_joiners))
        if missing:
            lines.append(" â€¢ ë¹ ì§„ ì¸ì›: " + ", ".join(missing))
        if not new_joiners and not missing:
            lines.append(" â€¢ ë³€ë™ ì—†ìŒ")

        # === ë¯¸ë°°ì • ì°¨ëŸ‰ (ì˜¤ì „ì— ìˆì—ˆëŠ”ë° ì˜¤í›„ì— ì—†ëŠ” ì°¨ëŸ‰ë§Œ)
        am_cars_1 = set(st.session_state.get("am_cars_1", []))
        am_cars_2 = set(st.session_state.get("am_cars_2", []))
        pm_cars_1 = {get_vehicle(x, veh1_map) for x in sud_a if get_vehicle(x, veh1_map)}
        pm_cars_2 = {get_vehicle(x, veh2_map) for x in auto_a if get_vehicle(x, veh2_map)}
        unassigned_1 = sorted([c for c in am_cars_1 if c and c not in pm_cars_1])
        unassigned_2 = sorted([c for c in am_cars_2 if c and c not in pm_cars_2])

        if unassigned_1 or unassigned_2:
            lines.append("")
            lines.append("ë¯¸ë°°ì • ì°¨ëŸ‰:")
            if unassigned_1:
                lines.append(" [1ì¢… ìˆ˜ë™]")
                for c in unassigned_1:
                    lines.append(f"  â€¢ {c} ë§ˆê°")
            if unassigned_2:
                lines.append(" [2ì¢… ìë™]")
                for c in unassigned_2:
                    lines.append(f"  â€¢ {c} ë§ˆê°")

        # ì¶œë ¥ + ë³µì‚¬
        result_text = "\n".join(lines)
        st.markdown("### ğŸ“‹ ì˜¤í›„ ê²°ê³¼")
        st.code(result_text, language="text")
        clipboard_copy_button("ğŸ“‹ ê²°ê³¼ ë³µì‚¬í•˜ê¸°", result_text)

        # âœ… ì „ì¼ ì €ì¥
        if save_check:
            data = {
                "ì—´ì‡ ": today_key,
                "êµì–‘_5êµì‹œ": gy5 or gy4 or gy3 or prev_gy5,
                "1ì¢…ìˆ˜ë™": (sud_a[-1] if sud_a else prev_sd)
            }
            save_json(PREV_FILE, data)
            st.success("ì „ì¼ê·¼ë¬´.json ì—…ë°ì´íŠ¸ ì™„ë£Œ âœ…")

    except Exception as e:
        st.error(f"ì˜¤í›„ ì˜¤ë¥˜: {e}")
