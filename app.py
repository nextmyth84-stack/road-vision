# app.py â€” ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì • v7.15.6 (ì™„ì „ë³¸)
import streamlit as st
from openai import OpenAI
import base64, re, json, os
from difflib import get_close_matches
import streamlit.components.v1 as components

# =====================================
# í˜ì´ì§€ ì„¤ì •
# =====================================
st.set_page_config(page_title="ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì •", layout="wide")
st.markdown("<h3 style='text-align:center; font-size:22px;'>ğŸš— ë„ë¡œì£¼í–‰ ê·¼ë¬´ìë™ë°°ì • v7.15.6</h3>", unsafe_allow_html=True)

# =====================================
# OpenAI ì´ˆê¸°í™”
# =====================================
try:
    client = OpenAI(api_key=st.secrets["general"]["OPENAI_API_KEY"])
except Exception:
    st.error("âš ï¸ OPENAI_API_KEY ì„¤ì • í•„ìš”")
    st.stop()
MODEL_NAME = "gpt-4o"

# =====================================
# íŒŒì¼ ìœ í‹¸
# =====================================
def save_json(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_json(path, default=None):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return default if default is not None else []

# =====================================
# íŒŒì¼ ê²½ë¡œ
# =====================================
PREV_FILE  = "ì „ì¼ê·¼ë¬´.json"
KEY_FILE   = "ì—´ì‡ ìˆœë²ˆ.json"
GY_FILE    = "êµì–‘ìˆœë²ˆ.json"
SUD_FILE   = "1ì¢…ìˆ˜ë™ìˆœë²ˆ.json"
VEH1_FILE  = "1ì¢…ì°¨ëŸ‰í‘œ.json"
VEH2_FILE  = "2ì¢…ì°¨ëŸ‰í‘œ.json"
COURSE_FILE= "ì½”ìŠ¤ì ê²€.json"
EMP_FILE   = "ê·¼ë¬´ìëª…ë‹¨.json"

# =====================================
# ê¸°ë³¸ ë°ì´í„°
# =====================================
default_key   = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ì„±ì—°","ê¹€ì§€ì€","ì•ˆìœ ë¯¸","ìœ¤ì—¬í—Œ","ìœ¤ì›ì‹¤","ì´ë‚˜ë˜","ì´í˜¸ì„","ì¡°ìœ¤ì˜","ì¡°ì •ë˜"]
default_gy    = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ë³‘ìš±","ê¹€ì„±ì—°","ê¹€ì£¼í˜„","ê¹€ì§€ì€","ì•ˆìœ ë¯¸","ì´í˜¸ì„","ì¡°ì •ë˜"]
default_sd    = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ì„±ì—°","ê¹€ì£¼í˜„","ì´í˜¸ì„","ì¡°ì •ë˜"]
default_veh1  = ["2í˜¸ ì¡°ì •ë˜","5í˜¸ ê¶Œí•œì†”","7í˜¸ ê¹€ë‚¨ê· ","8í˜¸ ì´í˜¸ì„","9í˜¸ ê¹€ì£¼í˜„","10í˜¸ ê¹€ì„±ì—°"]
default_veh2  = ["4í˜¸ ê¹€ë‚¨ê· ","5í˜¸ ê¹€ë³‘ìš±","6í˜¸ ê¹€ì§€ì€","12í˜¸ ì•ˆìœ ë¯¸","14í˜¸ ê¹€ë©´ì •","15í˜¸ ì´í˜¸ì„","17í˜¸ ê¹€ì„±ì—°","18í˜¸ ê¶Œí•œì†”","19í˜¸ ê¹€ì£¼í˜„","22í˜¸ ì¡°ì •ë˜"]
default_emp   = ["ê¶Œí•œì†”","ê¹€ë‚¨ê· ","ê¹€ë©´ì •","ê¹€ì„±ì—°","ê¹€ì§€ì€","ì•ˆìœ ë¯¸","ìœ¤ì—¬í—Œ","ìœ¤ì›ì‹¤","ì´ë‚˜ë˜","ì´í˜¸ì„","ì¡°ìœ¤ì˜","ì¡°ì •ë˜","ê¹€ë³‘ìš±","ê¹€ì£¼í˜„"]

# ìµœì´ˆ ìƒì„±
for f, data in [(KEY_FILE, default_key),(GY_FILE, default_gy),(SUD_FILE, default_sd),(VEH1_FILE, default_veh1),(VEH2_FILE, default_veh2),(EMP_FILE, default_emp)]:
    if not os.path.exists(f): save_json(f, data)
if not os.path.exists(PREV_FILE):   save_json(PREV_FILE, {"ì—´ì‡ ":"", "êµì–‘_5êµì‹œ":"", "1ì¢…ìˆ˜ë™":""})
if not os.path.exists(COURSE_FILE): save_json(COURSE_FILE, [])

# ì „ì¼ ë¶ˆëŸ¬ì˜¤ê¸°
_prev = load_json(PREV_FILE, {"ì—´ì‡ ":"", "êµì–‘_5êµì‹œ":"", "1ì¢…ìˆ˜ë™":""})
prev_key, prev_gyoyang5, prev_sudong = _prev.get("ì—´ì‡ ",""), _prev.get("êµì–‘_5êµì‹œ",""), _prev.get("1ì¢…ìˆ˜ë™","")
st.info(f"ì „ì¼ ë¶ˆëŸ¬ì˜´ â†’ ì—´ì‡ :{prev_key or '-'}, êµì–‘5:{prev_gyoyang5 or '-'}, 1ì¢…:{prev_sudong or '-'}")

# =====================================
# ìœ í‹¸
# =====================================
def normalize_name(s): 
    return re.sub(r"[^ê°€-í£]", "", re.sub(r"\(.*?\)", "", s or ""))

def parse_vehicle_map(lines):
    m = {}
    for line in lines:
        p = line.strip().split()
        if len(p) >= 2:
            m[" ".join(p[1:])] = p[0]
    return m

def correct_name(name, valid_names):
    n = normalize_name(name)
    valid_norms = [normalize_name(x) for x in valid_names]
    if n in valid_norms: return n
    match = get_close_matches(n, valid_norms, n=1, cutoff=0.75)
    return match[0] if match else n

def clipboard_copy_button(text: str):
    safe_text = text.replace("`","\\`").replace("${","\\${}")
    components.html(f"""
        <button id="copyBtn" style="padding:8px 14px;background:#4CAF50;color:white;border:none;border-radius:6px;cursor:pointer;margin-top:8px;">ğŸ“‹ ê²°ê³¼ ë³µì‚¬í•˜ê¸°</button>
        <script>
        const btn = document.getElementById("copyBtn");
        btn.addEventListener("click", () => {{
            navigator.clipboard.writeText(`{safe_text}`).then(() => {{
                const msg = document.createElement('div');
                msg.innerText = "âœ… ë³µì‚¬ ì™„ë£Œ!";
                msg.style.marginTop = "6px";
                msg.style.color = "#4CAF50";
                msg.style.fontWeight = "bold";
                btn.insertAdjacentElement('afterend', msg);
                setTimeout(() => msg.remove(), 1500);
            }});
        }});
        </script>
    """, height=70)

# =====================================
# ì‚¬ì´ë“œë°” (ìˆ¨ê¹€í˜• í¸ì§‘)
# =====================================
st.sidebar.header("ğŸ“‹ ìˆœë²ˆí‘œ / ì°¨ëŸ‰í‘œ / ì „ì¼ê°’ / ê·¼ë¬´ìëª…ë‹¨")

def _list(s): return [x.strip() for x in s.splitlines() if x.strip()]

# ìµœì‹  ë¡œë“œ (ì‚¬ì´ë“œë°” í‘œì‹œìš©)
key_order     = load_json(KEY_FILE, default_key)
gyoyang_order = load_json(GY_FILE, default_gy)
sudong_order  = load_json(SUD_FILE, default_sd)
veh1_lines    = load_json(VEH1_FILE, default_veh1)
veh2_lines    = load_json(VEH2_FILE, default_veh2)
employees     = load_json(EMP_FILE, default_emp)

with st.sidebar.expander("ğŸ”‘ ì—´ì‡  ìˆœë²ˆ", expanded=False):
    key_text = st.text_area("ì—´ì‡  ìˆœë²ˆ", "\n".join(key_order), height=180)
    if st.button("ğŸ’¾ ì—´ì‡ ìˆœë²ˆ ì €ì¥"): 
        save_json(KEY_FILE, _list(key_text)); st.sidebar.success("ì €ì¥ ì™„ë£Œ"); st.rerun()

with st.sidebar.expander("ğŸ“˜ êµì–‘ ìˆœë²ˆ", expanded=False):
    gy_text = st.text_area("êµì–‘ ìˆœë²ˆ", "\n".join(gyoyang_order), height=180)
    if st.button("ğŸ’¾ êµì–‘ìˆœë²ˆ ì €ì¥"):
        save_json(GY_FILE, _list(gy_text)); st.sidebar.success("ì €ì¥ ì™„ë£Œ"); st.rerun()

with st.sidebar.expander("ğŸ”§ 1ì¢… ìˆ˜ë™ ìˆœë²ˆ", expanded=False):
    sd_text = st.text_area("1ì¢… ìˆ˜ë™ ìˆœë²ˆ", "\n".join(sudong_order), height=150)
    sudong_count = st.radio("1ì¢… ìˆ˜ë™ ì¸ì›ìˆ˜", [1, 2], index=0, horizontal=True, key="sudong_count_radio")
    if st.button("ğŸ’¾ 1ì¢… ìˆœë²ˆ ì €ì¥"):
        save_json(SUD_FILE, _list(sd_text)); st.sidebar.success("ì €ì¥ ì™„ë£Œ"); st.rerun()

with st.sidebar.expander("ğŸš— ì°¨ëŸ‰í‘œ (1ì¢… ìˆ˜ë™)", expanded=False):
    v1_text = st.text_area("1ì¢… ìˆ˜ë™ ì°¨ëŸ‰í‘œ", "\n".join(veh1_lines), height=150)
    if st.button("ğŸ’¾ 1ì¢… ì°¨ëŸ‰í‘œ ì €ì¥"):
        save_json(VEH1_FILE, _list(v1_text)); st.sidebar.success("ì €ì¥ ì™„ë£Œ"); st.rerun()

with st.sidebar.expander("ğŸš˜ ì°¨ëŸ‰í‘œ (2ì¢… ìë™)", expanded=False):
    v2_text = st.text_area("2ì¢… ìë™ ì°¨ëŸ‰í‘œ", "\n".join(veh2_lines), height=180)
    if st.button("ğŸ’¾ 2ì¢… ì°¨ëŸ‰í‘œ ì €ì¥"):
        save_json(VEH2_FILE, _list(v2_text)); st.sidebar.success("ì €ì¥ ì™„ë£Œ"); st.rerun()

with st.sidebar.expander("ğŸ—“ ì „ì¼ ê°’ í™•ì¸/ìˆ˜ì •", expanded=False):
    prev_key = st.text_input("ì „ì¼ ì—´ì‡ ", value=prev_key)
    prev_gyoyang5 = st.text_input("ì „ì¼ êµì–‘5", value=prev_gyoyang5)
    prev_sudong = st.text_input("ì „ì¼ 1ì¢…ìˆ˜ë™", value=prev_sudong)
    if st.button("ğŸ’¾ ì „ì¼ê°’ ì €ì¥"):
        save_json(PREV_FILE, {"ì—´ì‡ ": prev_key, "êµì–‘_5êµì‹œ": prev_gyoyang5, "1ì¢…ìˆ˜ë™": prev_sudong})
        st.sidebar.success("ì €ì¥ ì™„ë£Œ")

with st.sidebar.expander("ğŸ‘¥ ì „ì²´ ê·¼ë¬´ìëª…ë‹¨ (OCR êµì •ìš©)", expanded=False):
    emp_text = st.text_area("ê·¼ë¬´ìëª…ë‹¨ (í•œ ì¤„ë‹¹ í•œ ëª…)", "\n".join(employees), height=200)
    if st.button("ğŸ’¾ ê·¼ë¬´ìëª…ë‹¨ ì €ì¥"):
        save_json(EMP_FILE, _list(emp_text)); st.sidebar.success("ì €ì¥ ì™„ë£Œ"); st.rerun()

# =====================================
# 2ï¸âƒ£ ê³µí†µ ìœ í‹¸/ë¡œë“œ
# =====================================
def mark_car(car): 
    return f"{car}" if car else ""

def get_vehicle(name, veh_map):
    nkey = normalize_name(name)
    for k, v in veh_map.items():
        if normalize_name(k) == nkey:
            return v
    return ""

def pick_next_from_cycle(cycle, last, allowed_norms: set):
    if not cycle: return None
    cyl_norm = [normalize_name(x) for x in cycle]
    last_norm = normalize_name(last)
    start = (cyl_norm.index(last_norm) + 1) % len(cycle) if last_norm in cyl_norm else 0
    for i in range(len(cycle) * 2):
        cand = cycle[(start + i) % len(cycle)]
        if normalize_name(cand) in allowed_norms:
            return cand
    return None

# ìµœì‹  ë°ì´í„° ì¬ë¡œë”© (ì‚¬ì´ë“œë°” ì €ì¥ ë°˜ì˜)
key_order     = load_json(KEY_FILE, default_key)
gyoyang_order = load_json(GY_FILE, default_gy)
sudong_order  = load_json(SUD_FILE, default_sd)
veh1_lines    = load_json(VEH1_FILE, default_veh1)
veh2_lines    = load_json(VEH2_FILE, default_veh2)
veh1 = parse_vehicle_map(veh1_lines)
veh2 = parse_vehicle_map(veh2_lines)
employees     = load_json(EMP_FILE, default_emp)

_prev = load_json(PREV_FILE, {"ì—´ì‡ ":"", "êµì–‘_5êµì‹œ":"", "1ì¢…ìˆ˜ë™":""})
prev_key, prev_gyoyang5, prev_sudong = _prev.get("ì—´ì‡ ",""), _prev.get("êµì–‘_5êµì‹œ",""), _prev.get("1ì¢…ìˆ˜ë™","")

# =====================================
# OCR (ê·¼ë¬´ì/ì½”ìŠ¤/ì œì™¸ì + ì˜¤íƒ€êµì •)
# =====================================
def gpt_extract(img_bytes, detect_excluded=True):
    """
    return:
      names        : ê´„í˜¸ ì œê±° + ê·¼ë¬´ìëª…ë‹¨ ê¸°ë°˜ ì˜¤íƒ€ êµì •ëœ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
      course_info  : [{"name":ì´ë¦„, "course":"Aí•©"/"Bë¶ˆ"}]  â†’ COURSE_FILE ì €ì¥
      excluded     : ê·¼ë¬´ì œì™¸ì (íœ´ê°€/êµìœ¡/ì¶œì¥/ê³µê°€/ì—°ê°€/ì—°ì°¨/ëŒë´„) ëª©ë¡ (êµì • ë°˜ì˜)
    """
    b64 = base64.b64encode(img_bytes).decode()
    user = (
        "ì´ ì´ë¯¸ì§€ëŠ” ìš´ì „ë©´í—ˆì‹œí—˜ ê·¼ë¬´í‘œì…ë‹ˆë‹¤.\n"
        "1) ë„ë¡œì£¼í–‰ ê·¼ë¬´ì ì´ë¦„ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.\n"
        "2) ì´ë¦„ ì˜† ê´„í˜¸(A-í•©, B-ë¶ˆ ë“±)ëŠ” ê·¸ëŒ€ë¡œ í¬í•¨í•´ ë°˜í™˜í•˜ì„¸ìš”.\n"
        "3) 'ì§€ì›','ì¸í„´','ì—°ìˆ˜' í¬í•¨ìëŠ” ì œì™¸í•˜ì„¸ìš”.\n"
    )
    if detect_excluded:
        user += "4) ìƒë‹¨ì˜ 'íœ´ê°€','êµìœ¡','ì¶œì¥','ê³µê°€','ì—°ê°€','ì—°ì°¨','ëŒë´„' ì¤„ì— ìˆëŠ” ì´ë¦„ì„ 'excluded' ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.\n"
    user += 'ë°˜í™˜ ì˜ˆì‹œ: {"names": ["ê¹€ë‚¨ê· (A-í•©)","ê¹€ì§€ì€(B-ë¶ˆ)","ì¡°ìœ¤ì˜"], "excluded": ["ì•ˆìœ ë¯¸","ê¹€ì„±ì—°"]}'

    try:
        res = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "í‘œì—ì„œ ê·¼ë¬´ì/ì½”ìŠ¤/ì œì™¸ì ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œ"},
                {"role": "user", "content": [
                    {"type": "text", "text": user},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
                ]}
            ],
        )
        raw = res.choices[0].message.content or "{}"
        js = json.loads(re.search(r"\{.*\}", raw, re.S).group(0))

        full = [n.strip() for n in js.get("names", []) if not re.search(r"(ì§€ì›|ì¸í„´|ì—°ìˆ˜)", n)]
        names_raw, course_info = [], []
        for n in full:
            m = re.search(r"(A[-â€“]?\s*í•©|B[-â€“]?\s*ë¶ˆ)", n)
            pure = re.sub(r"\(.*?\)", "", n).strip()
            names_raw.append(pure)
            if m:
                course_info.append({"name": pure, "course": m.group(1).replace(" ", "")})

        # ì˜¤íƒ€ êµì •
        valid = employees
        names = [correct_name(x, valid) for x in names_raw]

        # ê·¼ë¬´ì œì™¸ì
        excluded = js.get("excluded", []) if detect_excluded else []
        excluded = [correct_name(x, valid) for x in excluded]

        # ì½”ìŠ¤ê²°ê³¼ ì €ì¥
        save_json(COURSE_FILE, course_info)
        return names, course_info, excluded

    except Exception as e:
        st.error(f"OCR ì‹¤íŒ¨: {e}")
        return [], [], []

# =====================================
# ì˜¤ì „ ì´ë¯¸ì§€ ì—…ë¡œë“œ/OCR
# =====================================
st.markdown("<h4>1ï¸âƒ£ ì˜¤ì „ ê·¼ë¬´í‘œ ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
m_file = st.file_uploader("ğŸ“¸ ì˜¤ì „ ê·¼ë¬´í‘œ", type=["png","jpg","jpeg"], key="m_upl")

if st.button("ğŸ§  ì˜¤ì „ GPT ì¸ì‹"):
    if not m_file:
        st.warning("ì˜¤ì „ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        with st.spinner("ì˜¤ì „ ê·¼ë¬´í‘œ ë¶„ì„ ì¤‘..."):
            m_names, _course, excl = gpt_extract(m_file.read(), detect_excluded=True)
            st.session_state.m_names_raw = m_names
            st.session_state.excluded_auto = excl
            st.success(f"ì˜¤ì „ ì¸ì‹ ì™„ë£Œ: ê·¼ë¬´ì {len(m_names)}ëª…, ê·¼ë¬´ì œì™¸ {len(excl)}ëª… (ì½”ìŠ¤ ê²°ê³¼ ì €ì¥)")
        st.rerun()

# ê·¼ë¬´ì œì™¸ì (ìë™ì¶”ì¶œ í›„ ìˆ˜ì • ê°€ëŠ¥)
st.markdown("### ğŸš« ê·¼ë¬´ì œì™¸ì (ìë™ì¶”ì¶œ í›„ ìˆ˜ì • ê°€ëŠ¥)")
excluded_text = st.text_area("ìë™ ì¸ì‹ëœ ê·¼ë¬´ì œì™¸ì", "\n".join(st.session_state.get("excluded_auto", [])), height=100)
excluded = {x.strip() for x in excluded_text.splitlines() if x.strip()}

# ì˜¤ì „ ê·¼ë¬´ì ìˆ˜ì •
morning = st.text_area("ì˜¤ì „ ê·¼ë¬´ì (í•„ìš” ì‹œ ìˆ˜ì •)", "\n".join(st.session_state.get("m_names_raw", [])), height=150)
m_list = [x.strip() for x in morning.splitlines() if x.strip()]
m_allowed = {normalize_name(x) for x in m_list} - {normalize_name(x) for x in excluded}

# =====================================
# ì˜¤ì „ ë°°ì •
# =====================================
# sudong_countëŠ” ì‚¬ì´ë“œë°” ë¼ë””ì˜¤ì—ì„œ ë§¤ë²ˆ ê²°ì •ë¨
sudong_count = st.session_state.get("sudong_count_radio", 1)

if st.button("ğŸ“‹ ì˜¤ì „ ë°°ì • ìƒì„±"):
    try:
        lines = []

        # ğŸ”‘ ì—´ì‡ 
        today_key = pick_next_from_cycle(key_order, prev_key, m_allowed) if key_order else ""
        st.session_state.today_key = today_key

        # ğŸ§‘â€ğŸ« êµì–‘ 1Â·2
        gy1 = pick_next_from_cycle(gyoyang_order, prev_gyoyang5, m_allowed) if gyoyang_order else None
        gy1_norm = normalize_name(gy1) if gy1 else None
        gy2 = pick_next_from_cycle(gyoyang_order, gy1 or prev_gyoyang5, m_allowed - ({gy1_norm} if gy1_norm else set())) if gyoyang_order else None
        st.session_state.gyoyang_base_for_pm = gy2 or gy1 or prev_gyoyang5

        # ğŸ”§ 1ì¢… ìˆ˜ë™
        sud_m, last = [], prev_sudong
        for _ in range(sudong_count):
            pick = pick_next_from_cycle(sudong_order, last, m_allowed - {normalize_name(x) for x in sud_m})
            if not pick: break
            sud_m.append(pick); last = pick
        st.session_state.sudong_base_for_pm = sud_m[-1] if sud_m else prev_sudong

        # ğŸš— 2ì¢… ìë™
        sud_norms_m = {normalize_name(x) for x in sud_m}
        auto_m = [x for x in m_list if normalize_name(x) in (m_allowed - sud_norms_m)]

        # ì˜¤í›„ ë¹„êµ/ì°¨ëŸ‰ ì¶”ì  ì €ì¥
        st.session_state.morning_auto_names = auto_m + sud_m
        st.session_state.morning_cars_1 = [get_vehicle(x, veh1) for x in sud_m if get_vehicle(x, veh1)]
        st.session_state.morning_cars_2 = [get_vehicle(x, veh2) for x in auto_m if get_vehicle(x, veh2)]

        # ì¶œë ¥
        if today_key: lines.append(f"ì—´ì‡ : {today_key}")
        if gy1: lines.append(f"1êµì‹œ(êµì–‘): {gy1}")
        if gy2: lines.append(f"2êµì‹œ(êµì–‘): {gy2}")

        if sud_m:
            for nm in sud_m:
                lines.append(f"1ì¢…ìˆ˜ë™: {nm} {get_vehicle(nm, veh1) or ''}")
            if sudong_count == 2 and len(sud_m) < 2:
                lines.append("â€» ìˆ˜ë™ ê°€ëŠ¥ ì¸ì›ì´ 1ëª…ì…ë‹ˆë‹¤.")
        else:
            lines.append("1ì¢…ìˆ˜ë™: (ë°°ì •ì ì—†ìŒ)")

        if auto_m:
            lines.append("2ì¢… ìë™:")
            for nm in auto_m:
                lines.append(f" â€¢ {nm} {get_vehicle(nm, veh2) or ''}")
        else:
            lines.append("2ì¢… ìë™: (ë°°ì •ì ì—†ìŒ)")

        # ì½”ìŠ¤ì ê²€ (ì˜¤ì „ë§Œ)
        course_info = load_json(COURSE_FILE, [])
        if course_info:
            a_names = [x["name"] for x in course_info if "A" in x.get("course","")]
            b_names = [x["name"] for x in course_info if "B" in x.get("course","")]
            lines.append("")
            lines.append("ì½”ìŠ¤ì ê²€ ê²°ê³¼:")
            if a_names: lines.append(" â€¢ Aì½”ìŠ¤(í•©ê²©): " + ", ".join(a_names))
            if b_names: lines.append(" â€¢ Bì½”ìŠ¤(ë¶ˆí•©ê²©): " + ", ".join(b_names))

        result_text = "\n".join(lines)
        st.markdown("### ğŸ“‹ ì˜¤ì „ ê²°ê³¼")
        st.code(result_text, language="text")
        clipboard_copy_button(result_text)

    except Exception as e:
        st.error(f"ì˜¤ì „ ì˜¤ë¥˜: {e}")

# =====================================
# 3ï¸âƒ£ ì˜¤í›„ ê·¼ë¬´í‘œ ì—…ë¡œë“œ/OCR
# =====================================
st.markdown("<h4>2ï¸âƒ£ ì˜¤í›„ ê·¼ë¬´í‘œ ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
a_file = st.file_uploader("ğŸ“¸ ì˜¤í›„ ê·¼ë¬´í‘œ", type=["png","jpg","jpeg"], key="a_upl")

if st.button("ğŸ§  ì˜¤í›„ GPT ì¸ì‹"):
    if not a_file:
        st.warning("ì˜¤í›„ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        with st.spinner("ì˜¤í›„ ê·¼ë¬´í‘œ ë¶„ì„ ì¤‘..."):
            a_names, _course, _ = gpt_extract(a_file.read(), detect_excluded=False)
            st.session_state.a_names_raw = a_names
            st.success(f"ì˜¤í›„ ì¸ì‹ ì™„ë£Œ: ê·¼ë¬´ì {len(a_names)}ëª…")
        st.rerun()

afternoon = st.text_area("ì˜¤í›„ ê·¼ë¬´ì (í•„ìš” ì‹œ ìˆ˜ì •)", "\n".join(st.session_state.get("a_names_raw", [])), height=150)
a_list = [x.strip() for x in afternoon.splitlines() if x.strip()]

# ì œì™¸ì ì„¸ì´í”„ê°€ë“œ (ì˜¤ì „ ë‹¨ê³„ ê±´ë„ˆë›´ ê²½ìš° ëŒ€ë¹„)
excluded_defaults = set(st.session_state.get("excluded_auto", []))
excluded_norms = {normalize_name(x) for x in excluded_defaults}

# sudong_count ì¬í™•ì¸
sudong_count = st.session_state.get("sudong_count_radio", 1)

save_check = st.checkbox("ì´ ê²°ê³¼ë¥¼ ì „ì¼ê·¼ë¬´.jsonìœ¼ë¡œ ì €ì¥", value=True)

# =====================================
# ì˜¤í›„ ë°°ì • ìƒì„±
# =====================================
if st.button("ğŸ“‹ ì˜¤í›„ ë°°ì • ìƒì„±"):
    try:
        lines = []
        today_key  = st.session_state.get("today_key", prev_key)
        gy_start   = st.session_state.get("gyoyang_base_for_pm", prev_gyoyang5)
        sud_base   = st.session_state.get("sudong_base_for_pm", prev_sudong)

        a_norms = {normalize_name(x) for x in a_list} - excluded_norms

        # ğŸ§‘â€ğŸ« êµì–‘ 3Â·4Â·5
        used = set()
        gy3 = pick_next_from_cycle(gyoyang_order, gy_start, a_norms)
        if gy3: used.add(normalize_name(gy3))
        gy4 = pick_next_from_cycle(gyoyang_order, gy3 or gy_start, a_norms - used)
        if gy4: used.add(normalize_name(gy4))
        gy5 = pick_next_from_cycle(gyoyang_order, gy4 or gy3 or gy_start, a_norms - used)

        # ğŸ”§ 1ì¢… ìˆ˜ë™ (êµì–‘ ì¤‘ë³µ í—ˆìš©)
        sud_a, last = [], sud_base
        for _ in range(sudong_count):
            pick = pick_next_from_cycle(sudong_order, last, a_norms)
            if not pick: break
            sud_a.append(pick); last = pick

        # ğŸš— 2ì¢… ìë™
        sud_norms_a = {normalize_name(x) for x in sud_a}
        auto_a = [x for x in a_list if normalize_name(x) in (a_norms - sud_norms_a)]

        # ì¶œë ¥
        if today_key: lines.append(f"ì—´ì‡ : {today_key}")
        if gy3: lines.append(f"3êµì‹œ(êµì–‘): {gy3}")
        if gy4: lines.append(f"4êµì‹œ(êµì–‘): {gy4}")
        if gy5: lines.append(f"5êµì‹œ(êµì–‘): {gy5}")

        if sud_a:
            for nm in sud_a:
                lines.append(f"1ì¢…ìˆ˜ë™: {nm} {get_vehicle(nm, veh1) or ''}")
            if sudong_count == 2 and len(sud_a) < 2:
                lines.append("â€» ìˆ˜ë™ ê°€ëŠ¥ ì¸ì›ì´ 1ëª…ì…ë‹ˆë‹¤.")
        else:
            lines.append("1ì¢…ìˆ˜ë™: (ë°°ì •ì ì—†ìŒ)")

        if auto_a:
            lines.append("2ì¢… ìë™:")
            for nm in auto_a:
                lines.append(f" â€¢ {nm} {get_vehicle(nm, veh2) or ''}")
        else:
            lines.append("2ì¢… ìë™: (ë°°ì •ì ì—†ìŒ)")

        # ì˜¤ì „ ëŒ€ë¹„ ë¹„êµ
        lines.append("")
        lines.append("ì˜¤ì „ ëŒ€ë¹„ ë¹„êµ:")
        morning_auto_names = set(st.session_state.get("morning_auto_names", []))
        afternoon_auto_names = set(auto_a)
        afternoon_sudong_norms = {normalize_name(x) for x in sud_a}

        missing = []
        for nm in morning_auto_names:
            n_norm = normalize_name(nm)
            if n_norm not in {normalize_name(x) for x in afternoon_auto_names} and n_norm not in afternoon_sudong_norms:
                missing.append(nm)
        added = sorted(list(afternoon_auto_names - morning_auto_names))
        if added:   lines.append(" â€¢ ì¶”ê°€ ì¸ì›: " + ", ".join(added))
        if missing: lines.append(" â€¢ ë¹ ì§„ ì¸ì›: " + ", ".join(missing))
        if not added and not missing: lines.append(" â€¢ ë³€ë™ ì—†ìŒ")

        # ë¯¸ë°°ì • ì°¨ëŸ‰ (ì˜¤ì „ì— ìˆì—ˆëŠ”ë° ì˜¤í›„ì— ì—†ëŠ” ê²ƒë§Œ)
        m_cars_1 = set(st.session_state.get("morning_cars_1", []))
        m_cars_2 = set(st.session_state.get("morning_cars_2", []))
        a_cars_1 = {get_vehicle(x, veh1) for x in sud_a if get_vehicle(x, veh1)}
        a_cars_2 = {get_vehicle(x, veh2) for x in auto_a if get_vehicle(x, veh2)}
        unassigned_1 = sorted([c for c in m_cars_1 if c not in a_cars_1])
        unassigned_2 = sorted([c for c in m_cars_2 if c not in a_cars_2])
        if unassigned_1 or unassigned_2:
            lines.append("")
            lines.append("ë¯¸ë°°ì • ì°¨ëŸ‰:")
            if unassigned_1:
                lines.append(" [1ì¢… ìˆ˜ë™]")
                for c in unassigned_1: lines.append(f"  â€¢ {c} ë§ˆê°")
            if unassigned_2:
                lines.append(" [2ì¢… ìë™]")
                for c in unassigned_2: lines.append(f"  â€¢ {c} ë§ˆê°")

        # í‘œì‹œ + ë³µì‚¬
        result_text = "\n".join(lines)
        st.markdown("### ğŸ“‹ ì˜¤í›„ ê²°ê³¼")
        st.code(result_text, language="text")
        clipboard_copy_button(result_text)

        # ì „ì¼ ì €ì¥
        if save_check:
            data = {
                "ì—´ì‡ ": today_key,
                "êµì–‘_5êµì‹œ": gy5 or gy4 or gy3 or prev_gyoyang5,
                "1ì¢…ìˆ˜ë™": (sud_a[-1] if sud_a else prev_sudong)
            }
            save_json(PREV_FILE, data)
            st.success("ì „ì¼ê·¼ë¬´.json ì—…ë°ì´íŠ¸ ì™„ë£Œ âœ…")

    except Exception as e:
        st.error(f"ì˜¤í›„ ì˜¤ë¥˜: {e}")
